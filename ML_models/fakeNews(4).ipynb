{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fakeNews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFHRwd5FqLPj",
        "outputId": "df56cd9d-6c9c-4d4b-bc2d-ffd6e949cc64"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "print(\"Tensorflow Version\",tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Tensorflow Version 2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEkqjihqaXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b17b69-1d85-483c-cc88-d926f1a731b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7b_kKv4rRZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bb33c22-4d70-40d9-fdfb-b12d7833c562"
      },
      "source": [
        "!pip install scikit-learn>=0.24\n",
        "!pip install ktrain # for BERT model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.27.3.tar.gz (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 100 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain) (5.5.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Collecting syntok\n",
            "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
            "Collecting seqeval==0.0.19\n",
            "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
            "Collecting transformers<=4.3.3,>=4.0.0\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 46.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.8 MB/s \n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.88.0.tar.gz (26 kB)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.6.3)\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n",
            "Collecting keras-transformer>=0.39.0\n",
            "  Downloading keras-transformer-0.39.0.tar.gz (11 kB)\n",
            "Collecting keras-pos-embd>=0.12.0\n",
            "  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n",
            "Collecting keras-multi-head>=0.28.0\n",
            "  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n",
            "Collecting keras-layer-normalization>=0.15.0\n",
            "  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n",
            "Collecting keras-position-wise-feed-forward>=0.7.0\n",
            "  Downloading keras-position-wise-feed-forward-0.7.0.tar.gz (4.5 kB)\n",
            "Collecting keras-embed-sim>=0.9.0\n",
            "  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n",
            "Collecting keras-self-attention>=0.50.0\n",
            "  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.62.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (5.1.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ktrain) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain) (7.1.2)\n",
            "Building wheels for collected packages: ktrain, seqeval, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, syntok\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.27.3-py3-none-any.whl size=25283131 sha256=bdb25926a3baaeeb3824d42101addea8c69a19c6f0d9590ec89b2d04861f81b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/ef/e1/7da805d8a5944e8a3ac0553831d832c00b1800b848939849cb\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9929 sha256=555fc3eaabf89c7a2235acc54a2db8df881e86fabad2db75a2a7d55c2d7967a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.88.0-py3-none-any.whl size=34204 sha256=01601b0ef3c1b8d7b49e05523fce1e2440486e2fbebe4b6fcc38d9652d97157d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/90/cd/c038f2366929a3a5e3414a303b673e10235e802d871d29a835\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.39.0-py3-none-any.whl size=12842 sha256=8200a14efd465fd36a7abbca1079c6128017c761aa21a3ee1ba8b00848c12441\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/01/e0/5a1a14bed6726f2ed73f7917d2d2c2d4081d2c88426dea07ce\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4504 sha256=5b0fd49901694a63acb9ce84abb9e1fa74e6086974a1cb0c390f2911f05fde9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=698cbf084e1c5770f3b927972d8ba31f29fac842ca8b3237f63f60b3d34f7897\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15559 sha256=36f0b18cd82fadf6834d0f64471801cbaed4c2f32a3d4a865bd709af7dcf5eb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7469 sha256=77e17de4c661dce2e97bfece0157de0cbe0c8d00e7192bd2eff88c12a892bfb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-py3-none-any.whl size=5541 sha256=9afd7dd9fc12e2a1eaf19adbcb62719649847be0942c99007ee63a87a1102190\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/12/02/1ad455c4f181cda1a4e60c5445855853d5c2ea91f942586a04\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=6f47c2f2bd81213389b1521e71103dc467bfde8f34995c935628fffa4a45593a\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=3dc058acfe8234901e41322451eabfabedd7c0bddcb6659f59b00e5d86508886\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20917 sha256=f9492e98200203e883979a1012c33f695d32ee0cda615e8459195a846880821d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n",
            "Successfully built ktrain seqeval keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect syntok\n",
            "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, threadpoolctl, sacremoses, keras-transformer, whoosh, transformers, syntok, seqeval, sentencepiece, scikit-learn, langdetect, keras-bert, cchardet, ktrain\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed cchardet-2.1.7 keras-bert-0.88.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.39.0 ktrain-0.27.3 langdetect-1.0.9 sacremoses-0.0.46 scikit-learn-0.23.2 sentencepiece-0.1.96 seqeval-0.0.19 syntok-1.3.1 threadpoolctl-2.2.0 tokenizers-0.10.3 transformers-4.3.3 whoosh-2.7.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRqq1AHCrdDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cc0f4360-73f0-4f69-fa3a-29d47291d681"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/datagram/data/train_datam.csv')\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>403</td>\n",
              "      <td>Double concentré de tomates MUTTI, tube de 130g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>837</td>\n",
              "      <td>Pur jus de pommes pressées Pure Prémium TROPIC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>485</td>\n",
              "      <td>Rillettes de poulet rôti en cocotte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>363</td>\n",
              "      <td>My Eyes - Taille-crayons 3 diamètres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>591</td>\n",
              "      <td>Brosse à dents Inter Espaces médium AQUAFRESH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161875</th>\n",
              "      <td>162161</td>\n",
              "      <td>372</td>\n",
              "      <td>Lait pour le corps bio à l'aloé véra SO BIO, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161876</th>\n",
              "      <td>162162</td>\n",
              "      <td>510</td>\n",
              "      <td>Hacao aux crevettes + 2 sauces soja, 200g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161877</th>\n",
              "      <td>162163</td>\n",
              "      <td>587</td>\n",
              "      <td>Studio Line - Indestuctible 9, gel fixation ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161878</th>\n",
              "      <td>162164</td>\n",
              "      <td>411</td>\n",
              "      <td>BISCUITS POIREAU 100G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161879</th>\n",
              "      <td>162165</td>\n",
              "      <td>377</td>\n",
              "      <td>Boulettes sauce pour chat au poulet, boîte de ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>161880 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                              pname\n",
              "0                0  ...    Double concentré de tomates MUTTI, tube de 130g\n",
              "1                1  ...  Pur jus de pommes pressées Pure Prémium TROPIC...\n",
              "2                2  ...                Rillettes de poulet rôti en cocotte\n",
              "3                3  ...               My Eyes - Taille-crayons 3 diamètres\n",
              "4                4  ...      Brosse à dents Inter Espaces médium AQUAFRESH\n",
              "...            ...  ...                                                ...\n",
              "161875      162161  ...  Lait pour le corps bio à l'aloé véra SO BIO, 4...\n",
              "161876      162162  ...          Hacao aux crevettes + 2 sauces soja, 200g\n",
              "161877      162163  ...  Studio Line - Indestuctible 9, gel fixation ex...\n",
              "161878      162164  ...                              BISCUITS POIREAU 100G\n",
              "161879      162165  ...  Boulettes sauce pour chat au poulet, boîte de ...\n",
              "\n",
              "[161880 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZCiOCf4reT7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3030e504-c6ee-4552-a569-00717aa5cda1"
      },
      "source": [
        "del df['Unnamed: 0']\n",
        "df.columns = ['category_id', 'pname']\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>403</td>\n",
              "      <td>Double concentré de tomates MUTTI, tube de 130g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>837</td>\n",
              "      <td>Pur jus de pommes pressées Pure Prémium TROPIC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>485</td>\n",
              "      <td>Rillettes de poulet rôti en cocotte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>363</td>\n",
              "      <td>My Eyes - Taille-crayons 3 diamètres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>591</td>\n",
              "      <td>Brosse à dents Inter Espaces médium AQUAFRESH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category_id                                              pname\n",
              "0          403    Double concentré de tomates MUTTI, tube de 130g\n",
              "1          837  Pur jus de pommes pressées Pure Prémium TROPIC...\n",
              "2          485                Rillettes de poulet rôti en cocotte\n",
              "3          363               My Eyes - Taille-crayons 3 diamètres\n",
              "4          591      Brosse à dents Inter Espaces médium AQUAFRESH"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epp1uKaDvBB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "aebeb5ea-5044-4bdf-9bf4-5534e5fc3f0e"
      },
      "source": [
        "\"\"\"import random\n",
        "random_idx_list = [random.randint(1,len(df.tweet)) for i in range(10)] # creates random indexes to choose from dataframe\n",
        "df.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it\"\"\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import random\\nrandom_idx_list = [random.randint(1,len(df.tweet)) for i in range(10)] # creates random indexes to choose from dataframe\\ndf.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhMZ-NfqvDd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7659726a-9940-43f4-8c17-fdfa656804e3"
      },
      "source": [
        "\"\"\"stop_words = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stop_words = stopwords.words(\\'english\\')\\nstemmer = SnowballStemmer(\\'english\\')\\n\\ntext_cleaning_re = \"@\\\\S+|https?:\\\\S+|http?:\\\\S|[^A-Za-z0-9]+'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkzW7tNg2SZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8d6fa22c-2bd7-4dd7-aebe-fba1e553e928"
      },
      "source": [
        "\"\"\"def preprocess(text, stem=False):\n",
        "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    if token not in stop_words:\n",
        "      if stem:\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else:\n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def preprocess(text, stem=False):\\n  text = re.sub(text_cleaning_re, \\' \\', str(text).lower()).strip()\\n  tokens = []\\n  for token in text.split():\\n    if token not in stop_words:\\n      if stem:\\n        tokens.append(stemmer.stem(token))\\n      else:\\n        tokens.append(token)\\n  return \" \".join(tokens)'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep0PPiU_2WUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b654d262-4a07-4e48-be02-98f0b31c1090"
      },
      "source": [
        "\"\"\"df.tweet = df.tweet.apply(lambda x: preprocess(x))\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'df.tweet = df.tweet.apply(lambda x: preprocess(x))'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpCLgCQA2bph"
      },
      "source": [
        "TRAIN_SIZE = 0.8\n",
        "MAX_NB_WORDS = 100000\n",
        "MAX_SEQUENCE_LENGTH = 30"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kKVkpLxY2j7"
      },
      "source": [
        "df['tweet'] = df['pname'] \n",
        "df['label'] = df['category_id']  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wfEHZlE2dy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda35c62-736f-4264-c9e2-177afe2a4ce8"
      },
      "source": [
        "train_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE,\n",
        "                                         random_state=7) # Splits Dataset into Training and Testing set\n",
        "\n",
        "test_data = test_data.groupby('category_id').filter(lambda x : (x['category_id'].count()>=10).any())\n",
        "train_data = train_data.groupby('category_id').filter(lambda x : (x['category_id'].count()>=10).any())                               \n",
        "print(\"Train Data size:\", len(train_data))\n",
        "print(\"Test Data size\", len(test_data))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data size: 129504\n",
            "Test Data size 32205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLjZamwG2fXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "d3f452ba-78a3-4810-895f-c1338edfae4d"
      },
      "source": [
        "train_data.head(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27381</th>\n",
              "      <td>377</td>\n",
              "      <td>Fines mousses au saumon-poulet-dinde-rognons p...</td>\n",
              "      <td>Fines mousses au saumon-poulet-dinde-rognons p...</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158645</th>\n",
              "      <td>393</td>\n",
              "      <td>Haricots beurre extra-fins d'Aucy, 2x4/4, 880g</td>\n",
              "      <td>Haricots beurre extra-fins d'Aucy, 2x4/4, 880g</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44090</th>\n",
              "      <td>349</td>\n",
              "      <td>Savon détachant écologique à l'huile d'olive b...</td>\n",
              "      <td>Savon détachant écologique à l'huile d'olive b...</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23089</th>\n",
              "      <td>467</td>\n",
              "      <td>*BLEU DES NEIGES 500G</td>\n",
              "      <td>*BLEU DES NEIGES 500G</td>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161552</th>\n",
              "      <td>386</td>\n",
              "      <td>Olives vertes farcies au poivron goût piment</td>\n",
              "      <td>Olives vertes farcies au poivron goût piment</td>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49802</th>\n",
              "      <td>610</td>\n",
              "      <td>Mouchoirs</td>\n",
              "      <td>Mouchoirs</td>\n",
              "      <td>610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11173</th>\n",
              "      <td>526</td>\n",
              "      <td>Tarte au chocolat Pierron 400g</td>\n",
              "      <td>Tarte au chocolat Pierron 400g</td>\n",
              "      <td>526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87452</th>\n",
              "      <td>363</td>\n",
              "      <td>Trousse petit modèle, Ca612 DESSANGE</td>\n",
              "      <td>Trousse petit modèle, Ca612 DESSANGE</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116463</th>\n",
              "      <td>600</td>\n",
              "      <td>Rasoir pour homme sensitive skinguard GILLETTE...</td>\n",
              "      <td>Rasoir pour homme sensitive skinguard GILLETTE...</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102295</th>\n",
              "      <td>597</td>\n",
              "      <td>Gel douche tonifiant NATURA SIBERICA, 400ml</td>\n",
              "      <td>Gel douche tonifiant NATURA SIBERICA, 400ml</td>\n",
              "      <td>597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category_id  ... label\n",
              "27381           377  ...   377\n",
              "158645          393  ...   393\n",
              "44090           349  ...   349\n",
              "23089           467  ...   467\n",
              "161552          386  ...   386\n",
              "49802           610  ...   610\n",
              "11173           526  ...   526\n",
              "87452           363  ...   363\n",
              "116463          600  ...   600\n",
              "102295          597  ...   597\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbKZwRWa2rU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75197fdf-2e77-4194-8a76-976c8966ceab"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data.tweet)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size : 28867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0cCYC62uAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34243379-4e99-4716-9114-6e2ecd66ec8d"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet),\n",
        "                        maxlen = MAX_SEQUENCE_LENGTH)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet),\n",
        "                       maxlen = MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"Training X Shape:\",x_train.shape)\n",
        "print(\"Testing X Shape:\",x_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training X Shape: (129504, 30)\n",
            "Testing X Shape: (32205, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJmhPsoE2xAq"
      },
      "source": [
        "labels = train_data.label.unique().tolist()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwzmdjMB2zKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8cd9fa9-86ac-4d65-ee30-aa5f1f8075f3"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_data.label.to_list())\n",
        "\n",
        "y_train = encoder.transform(train_data.label.to_list())\n",
        "y_test = encoder.transform(test_data.label.to_list())\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (129504, 1)\n",
            "y_test shape: (32205, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpflnyNl20-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2633a5f-3631-4821-87c7-9e5edcc7e05e"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-26 07:34:59--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-26 07:35:00--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-26 07:35:00--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.04MB/s    in 2m 40s  \n",
            "\n",
            "2021-09-26 07:37:41 (5.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvws1aWI23Aj"
      },
      "source": [
        "GLOVE_EMB = '/content/glove.6B.300d.txt'\n",
        "EMBEDDING_DIM = 300\n",
        "LR = 1e-3\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 150\n",
        "MODEL_PATH = '/content/drive/MyDrive/Classroom/best_model.hdf5'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M7c5ngg324Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cbc8c8-3ec4-4338-eeab-7028387a279f"
      },
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open(GLOVE_EMB)\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = value = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2auYeto364c"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4g2k7NH4IEK"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(vocab_size,\n",
        "                                          EMBEDDING_DIM,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                          trainable=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_9ti4_4KFX"
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN8xtMhc4NUz"
      },
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedding_sequences = embedding_layer(sequence_input)\n",
        "x = SpatialDropout1D(0.2)(embedding_sequences)\n",
        "x = Conv1D(64, 5, activation='relu')(x)\n",
        "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(len(labels), activation='sigmoid')(x)\n",
        "model = tf.keras.Model(sequence_input, outputs)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H_fd2sL4Pnv"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1,\n",
        "                                     min_lr = 0.01,\n",
        "                                     monitor = 'val_loss',\n",
        "                                     verbose = 1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kZWwp0Y4TDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ae04ef-cb32-4319-cf7d-53c28cd31d5b"
      },
      "source": [
        "print(\"Training on GPU...\") if tf.test.is_gpu_available() else print(\"Training on CPU...\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-d4a4e34b7f9f>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "Training on CPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3WHp5M84Xev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f130465d-ac8c-4b04-93b5-5831f810e403"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "127/127 [==============================] - 133s 1s/step - loss: 4.1237 - accuracy: 0.1770 - val_loss: 2.6002 - val_accuracy: 0.4118\n",
            "Epoch 2/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 2.5290 - accuracy: 0.4258 - val_loss: 1.9432 - val_accuracy: 0.5450\n",
            "Epoch 3/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 2.1045 - accuracy: 0.5055 - val_loss: 1.6894 - val_accuracy: 0.5974\n",
            "Epoch 4/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 1.8954 - accuracy: 0.5497 - val_loss: 1.5405 - val_accuracy: 0.6287\n",
            "Epoch 5/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 1.7634 - accuracy: 0.5744 - val_loss: 1.4397 - val_accuracy: 0.6487\n",
            "Epoch 6/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.6698 - accuracy: 0.5952 - val_loss: 1.3782 - val_accuracy: 0.6652\n",
            "Epoch 7/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.5923 - accuracy: 0.6104 - val_loss: 1.3227 - val_accuracy: 0.6751\n",
            "Epoch 8/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 1.5386 - accuracy: 0.6216 - val_loss: 1.2767 - val_accuracy: 0.6857\n",
            "Epoch 9/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.4814 - accuracy: 0.6331 - val_loss: 1.2417 - val_accuracy: 0.6942\n",
            "Epoch 10/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.4422 - accuracy: 0.6396 - val_loss: 1.2117 - val_accuracy: 0.6966\n",
            "Epoch 11/150\n",
            "127/127 [==============================] - 127s 1000ms/step - loss: 1.4064 - accuracy: 0.6489 - val_loss: 1.1869 - val_accuracy: 0.7064\n",
            "Epoch 12/150\n",
            "127/127 [==============================] - 127s 1000ms/step - loss: 1.3746 - accuracy: 0.6532 - val_loss: 1.1699 - val_accuracy: 0.7061\n",
            "Epoch 13/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 1.3404 - accuracy: 0.6604 - val_loss: 1.1479 - val_accuracy: 0.7112\n",
            "Epoch 14/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.3167 - accuracy: 0.6654 - val_loss: 1.1375 - val_accuracy: 0.7132\n",
            "Epoch 15/150\n",
            "127/127 [==============================] - 127s 1000ms/step - loss: 1.2929 - accuracy: 0.6710 - val_loss: 1.1108 - val_accuracy: 0.7215\n",
            "Epoch 16/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.2687 - accuracy: 0.6759 - val_loss: 1.1050 - val_accuracy: 0.7241\n",
            "Epoch 17/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.2486 - accuracy: 0.6800 - val_loss: 1.0841 - val_accuracy: 0.7274\n",
            "Epoch 18/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.2338 - accuracy: 0.6837 - val_loss: 1.0794 - val_accuracy: 0.7284\n",
            "Epoch 19/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.2108 - accuracy: 0.6883 - val_loss: 1.0723 - val_accuracy: 0.7290\n",
            "Epoch 20/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.1980 - accuracy: 0.6911 - val_loss: 1.0532 - val_accuracy: 0.7350\n",
            "Epoch 21/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.1885 - accuracy: 0.6934 - val_loss: 1.0444 - val_accuracy: 0.7361\n",
            "Epoch 22/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.1680 - accuracy: 0.6980 - val_loss: 1.0371 - val_accuracy: 0.7392\n",
            "Epoch 23/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.1559 - accuracy: 0.7003 - val_loss: 1.0337 - val_accuracy: 0.7403\n",
            "Epoch 24/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.1459 - accuracy: 0.7022 - val_loss: 1.0261 - val_accuracy: 0.7412\n",
            "Epoch 25/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.1319 - accuracy: 0.7046 - val_loss: 1.0108 - val_accuracy: 0.7442\n",
            "Epoch 26/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.1212 - accuracy: 0.7071 - val_loss: 1.0156 - val_accuracy: 0.7419\n",
            "Epoch 27/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 1.1093 - accuracy: 0.7086 - val_loss: 1.0146 - val_accuracy: 0.7421\n",
            "Epoch 28/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0970 - accuracy: 0.7115 - val_loss: 0.9987 - val_accuracy: 0.7465\n",
            "Epoch 29/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.0894 - accuracy: 0.7138 - val_loss: 0.9950 - val_accuracy: 0.7490\n",
            "Epoch 30/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 1.0890 - accuracy: 0.7130 - val_loss: 0.9868 - val_accuracy: 0.7518\n",
            "Epoch 31/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.0739 - accuracy: 0.7177 - val_loss: 0.9883 - val_accuracy: 0.7503\n",
            "Epoch 32/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0641 - accuracy: 0.7191 - val_loss: 0.9865 - val_accuracy: 0.7503\n",
            "Epoch 33/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 1.0580 - accuracy: 0.7200 - val_loss: 0.9813 - val_accuracy: 0.7505\n",
            "Epoch 34/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0548 - accuracy: 0.7209 - val_loss: 0.9686 - val_accuracy: 0.7538\n",
            "Epoch 35/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0442 - accuracy: 0.7232 - val_loss: 0.9746 - val_accuracy: 0.7534\n",
            "Epoch 36/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0393 - accuracy: 0.7244 - val_loss: 0.9635 - val_accuracy: 0.7542\n",
            "Epoch 37/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0314 - accuracy: 0.7262 - val_loss: 0.9642 - val_accuracy: 0.7555\n",
            "Epoch 38/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.0212 - accuracy: 0.7285 - val_loss: 0.9569 - val_accuracy: 0.7562\n",
            "Epoch 39/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 1.0160 - accuracy: 0.7301 - val_loss: 0.9589 - val_accuracy: 0.7553\n",
            "Epoch 40/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0097 - accuracy: 0.7310 - val_loss: 0.9508 - val_accuracy: 0.7586\n",
            "Epoch 41/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 1.0010 - accuracy: 0.7319 - val_loss: 0.9492 - val_accuracy: 0.7583\n",
            "Epoch 42/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.9975 - accuracy: 0.7330 - val_loss: 0.9487 - val_accuracy: 0.7607\n",
            "Epoch 43/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.9908 - accuracy: 0.7350 - val_loss: 0.9490 - val_accuracy: 0.7614\n",
            "Epoch 44/150\n",
            "127/127 [==============================] - 127s 1000ms/step - loss: 0.9904 - accuracy: 0.7344 - val_loss: 0.9431 - val_accuracy: 0.7611\n",
            "Epoch 45/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 0.9868 - accuracy: 0.7346 - val_loss: 0.9379 - val_accuracy: 0.7621\n",
            "Epoch 46/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 0.9772 - accuracy: 0.7364 - val_loss: 0.9347 - val_accuracy: 0.7633\n",
            "Epoch 47/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.9682 - accuracy: 0.7394 - val_loss: 0.9346 - val_accuracy: 0.7648\n",
            "Epoch 48/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.9668 - accuracy: 0.7396 - val_loss: 0.9380 - val_accuracy: 0.7630\n",
            "Epoch 49/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.9654 - accuracy: 0.7392 - val_loss: 0.9251 - val_accuracy: 0.7658\n",
            "Epoch 50/150\n",
            "127/127 [==============================] - 129s 1s/step - loss: 0.9525 - accuracy: 0.7428 - val_loss: 0.9227 - val_accuracy: 0.7665\n",
            "Epoch 51/150\n",
            "127/127 [==============================] - 130s 1s/step - loss: 0.9520 - accuracy: 0.7441 - val_loss: 0.9210 - val_accuracy: 0.7683\n",
            "Epoch 52/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.9445 - accuracy: 0.7456 - val_loss: 0.9241 - val_accuracy: 0.7668\n",
            "Epoch 53/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.9440 - accuracy: 0.7451 - val_loss: 0.9212 - val_accuracy: 0.7699\n",
            "Epoch 54/150\n",
            "127/127 [==============================] - 126s 995ms/step - loss: 0.9418 - accuracy: 0.7458 - val_loss: 0.9196 - val_accuracy: 0.7677\n",
            "Epoch 55/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 0.9387 - accuracy: 0.7451 - val_loss: 0.9158 - val_accuracy: 0.7688\n",
            "Epoch 56/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.9286 - accuracy: 0.7470 - val_loss: 0.9209 - val_accuracy: 0.7696\n",
            "Epoch 57/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.9266 - accuracy: 0.7467 - val_loss: 0.9137 - val_accuracy: 0.7689\n",
            "Epoch 58/150\n",
            "127/127 [==============================] - 126s 995ms/step - loss: 0.9275 - accuracy: 0.7479 - val_loss: 0.9103 - val_accuracy: 0.7705\n",
            "Epoch 59/150\n",
            "127/127 [==============================] - 126s 995ms/step - loss: 0.9217 - accuracy: 0.7489 - val_loss: 0.9096 - val_accuracy: 0.7692\n",
            "Epoch 60/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.9190 - accuracy: 0.7499 - val_loss: 0.9105 - val_accuracy: 0.7706\n",
            "Epoch 61/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.9184 - accuracy: 0.7498 - val_loss: 0.9045 - val_accuracy: 0.7706\n",
            "Epoch 62/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.9082 - accuracy: 0.7524 - val_loss: 0.9163 - val_accuracy: 0.7670\n",
            "Epoch 63/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.9127 - accuracy: 0.7504 - val_loss: 0.9059 - val_accuracy: 0.7720\n",
            "Epoch 64/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.9052 - accuracy: 0.7529 - val_loss: 0.8994 - val_accuracy: 0.7721\n",
            "Epoch 65/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.9032 - accuracy: 0.7527 - val_loss: 0.9034 - val_accuracy: 0.7706\n",
            "Epoch 66/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 0.9002 - accuracy: 0.7537 - val_loss: 0.9031 - val_accuracy: 0.7715\n",
            "Epoch 67/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.8958 - accuracy: 0.7537 - val_loss: 0.8985 - val_accuracy: 0.7738\n",
            "Epoch 68/150\n",
            "127/127 [==============================] - 126s 995ms/step - loss: 0.8903 - accuracy: 0.7562 - val_loss: 0.9001 - val_accuracy: 0.7728\n",
            "Epoch 69/150\n",
            "127/127 [==============================] - 126s 996ms/step - loss: 0.8900 - accuracy: 0.7558 - val_loss: 0.8955 - val_accuracy: 0.7747\n",
            "Epoch 70/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.8862 - accuracy: 0.7556 - val_loss: 0.8919 - val_accuracy: 0.7762\n",
            "Epoch 71/150\n",
            "127/127 [==============================] - 129s 1s/step - loss: 0.8836 - accuracy: 0.7575 - val_loss: 0.9012 - val_accuracy: 0.7749\n",
            "Epoch 72/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.8796 - accuracy: 0.7579 - val_loss: 0.8940 - val_accuracy: 0.7750\n",
            "Epoch 73/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.8789 - accuracy: 0.7586 - val_loss: 0.9008 - val_accuracy: 0.7748\n",
            "Epoch 74/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.8736 - accuracy: 0.7596 - val_loss: 0.8960 - val_accuracy: 0.7746\n",
            "Epoch 75/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8722 - accuracy: 0.7593 - val_loss: 0.8935 - val_accuracy: 0.7735\n",
            "Epoch 76/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8722 - accuracy: 0.7592 - val_loss: 0.9029 - val_accuracy: 0.7735\n",
            "Epoch 77/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8684 - accuracy: 0.7614 - val_loss: 0.8861 - val_accuracy: 0.7780\n",
            "Epoch 78/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8653 - accuracy: 0.7613 - val_loss: 0.8887 - val_accuracy: 0.7758\n",
            "Epoch 79/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8594 - accuracy: 0.7626 - val_loss: 0.8876 - val_accuracy: 0.7776\n",
            "Epoch 80/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.8600 - accuracy: 0.7631 - val_loss: 0.8826 - val_accuracy: 0.7777\n",
            "Epoch 81/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8591 - accuracy: 0.7627 - val_loss: 0.8853 - val_accuracy: 0.7778\n",
            "Epoch 82/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8540 - accuracy: 0.7641 - val_loss: 0.8853 - val_accuracy: 0.7801\n",
            "Epoch 83/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8506 - accuracy: 0.7649 - val_loss: 0.8856 - val_accuracy: 0.7777\n",
            "Epoch 84/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8483 - accuracy: 0.7653 - val_loss: 0.8827 - val_accuracy: 0.7788\n",
            "Epoch 85/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8513 - accuracy: 0.7646 - val_loss: 0.8789 - val_accuracy: 0.7803\n",
            "Epoch 86/150\n",
            "127/127 [==============================] - 126s 996ms/step - loss: 0.8478 - accuracy: 0.7646 - val_loss: 0.8853 - val_accuracy: 0.7781\n",
            "Epoch 87/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 0.8442 - accuracy: 0.7651 - val_loss: 0.8790 - val_accuracy: 0.7794\n",
            "Epoch 88/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.8418 - accuracy: 0.7668 - val_loss: 0.8794 - val_accuracy: 0.7803\n",
            "Epoch 89/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.8406 - accuracy: 0.7655 - val_loss: 0.8833 - val_accuracy: 0.7800\n",
            "Epoch 90/150\n",
            "127/127 [==============================] - 127s 997ms/step - loss: 0.8397 - accuracy: 0.7672 - val_loss: 0.8757 - val_accuracy: 0.7814\n",
            "Epoch 91/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 0.8368 - accuracy: 0.7669 - val_loss: 0.8779 - val_accuracy: 0.7813\n",
            "Epoch 92/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8295 - accuracy: 0.7690 - val_loss: 0.8827 - val_accuracy: 0.7775\n",
            "Epoch 93/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.8315 - accuracy: 0.7687 - val_loss: 0.8757 - val_accuracy: 0.7806\n",
            "Epoch 94/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.8292 - accuracy: 0.7690 - val_loss: 0.8799 - val_accuracy: 0.7802\n",
            "Epoch 95/150\n",
            "127/127 [==============================] - 127s 999ms/step - loss: 0.8309 - accuracy: 0.7686 - val_loss: 0.8793 - val_accuracy: 0.7812\n",
            "Epoch 96/150\n",
            "127/127 [==============================] - 127s 996ms/step - loss: 0.8302 - accuracy: 0.7688 - val_loss: 0.8681 - val_accuracy: 0.7834\n",
            "Epoch 97/150\n",
            "127/127 [==============================] - 127s 998ms/step - loss: 0.8215 - accuracy: 0.7714 - val_loss: 0.8764 - val_accuracy: 0.7819\n",
            "Epoch 98/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8222 - accuracy: 0.7703 - val_loss: 0.8767 - val_accuracy: 0.7815\n",
            "Epoch 99/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8176 - accuracy: 0.7718 - val_loss: 0.8760 - val_accuracy: 0.7807\n",
            "Epoch 100/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8235 - accuracy: 0.7695 - val_loss: 0.8768 - val_accuracy: 0.7808\n",
            "Epoch 101/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.8160 - accuracy: 0.7726 - val_loss: 0.8674 - val_accuracy: 0.7832\n",
            "Epoch 102/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8131 - accuracy: 0.7721 - val_loss: 0.8763 - val_accuracy: 0.7822\n",
            "Epoch 103/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8183 - accuracy: 0.7718 - val_loss: 0.8702 - val_accuracy: 0.7830\n",
            "Epoch 104/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8133 - accuracy: 0.7722 - val_loss: 0.8711 - val_accuracy: 0.7804\n",
            "Epoch 105/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.8079 - accuracy: 0.7741 - val_loss: 0.8720 - val_accuracy: 0.7842\n",
            "Epoch 106/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8091 - accuracy: 0.7725 - val_loss: 0.8661 - val_accuracy: 0.7863\n",
            "Epoch 107/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8069 - accuracy: 0.7733 - val_loss: 0.8672 - val_accuracy: 0.7835\n",
            "Epoch 108/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8013 - accuracy: 0.7750 - val_loss: 0.8649 - val_accuracy: 0.7850\n",
            "Epoch 109/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.8050 - accuracy: 0.7744 - val_loss: 0.8615 - val_accuracy: 0.7850\n",
            "Epoch 110/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7987 - accuracy: 0.7765 - val_loss: 0.8638 - val_accuracy: 0.7864\n",
            "Epoch 111/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7950 - accuracy: 0.7764 - val_loss: 0.8693 - val_accuracy: 0.7845\n",
            "Epoch 112/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7959 - accuracy: 0.7771 - val_loss: 0.8685 - val_accuracy: 0.7835\n",
            "Epoch 113/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7968 - accuracy: 0.7758 - val_loss: 0.8613 - val_accuracy: 0.7857\n",
            "Epoch 114/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7905 - accuracy: 0.7774 - val_loss: 0.8621 - val_accuracy: 0.7847\n",
            "Epoch 115/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7916 - accuracy: 0.7785 - val_loss: 0.8612 - val_accuracy: 0.7855\n",
            "Epoch 116/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7928 - accuracy: 0.7767 - val_loss: 0.8646 - val_accuracy: 0.7874\n",
            "Epoch 117/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7892 - accuracy: 0.7775 - val_loss: 0.8620 - val_accuracy: 0.7864\n",
            "Epoch 118/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7843 - accuracy: 0.7780 - val_loss: 0.8593 - val_accuracy: 0.7876\n",
            "Epoch 119/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7834 - accuracy: 0.7805 - val_loss: 0.8622 - val_accuracy: 0.7874\n",
            "Epoch 120/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7867 - accuracy: 0.7784 - val_loss: 0.8530 - val_accuracy: 0.7892\n",
            "Epoch 121/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7811 - accuracy: 0.7799 - val_loss: 0.8633 - val_accuracy: 0.7887\n",
            "Epoch 122/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7774 - accuracy: 0.7807 - val_loss: 0.8639 - val_accuracy: 0.7878\n",
            "Epoch 123/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7807 - accuracy: 0.7802 - val_loss: 0.8660 - val_accuracy: 0.7875\n",
            "Epoch 124/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7837 - accuracy: 0.7785 - val_loss: 0.8601 - val_accuracy: 0.7876\n",
            "Epoch 125/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7813 - accuracy: 0.7799 - val_loss: 0.8613 - val_accuracy: 0.7875\n",
            "Epoch 126/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7740 - accuracy: 0.7819 - val_loss: 0.8622 - val_accuracy: 0.7869\n",
            "Epoch 127/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7755 - accuracy: 0.7804 - val_loss: 0.8525 - val_accuracy: 0.7876\n",
            "Epoch 128/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7722 - accuracy: 0.7815 - val_loss: 0.8619 - val_accuracy: 0.7872\n",
            "Epoch 129/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7751 - accuracy: 0.7816 - val_loss: 0.8649 - val_accuracy: 0.7876\n",
            "Epoch 130/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7751 - accuracy: 0.7811 - val_loss: 0.8623 - val_accuracy: 0.7890\n",
            "Epoch 131/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7743 - accuracy: 0.7811 - val_loss: 0.8555 - val_accuracy: 0.7897\n",
            "Epoch 132/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7746 - accuracy: 0.7810 - val_loss: 0.8533 - val_accuracy: 0.7905\n",
            "Epoch 133/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7679 - accuracy: 0.7827 - val_loss: 0.8520 - val_accuracy: 0.7913\n",
            "Epoch 134/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7665 - accuracy: 0.7825 - val_loss: 0.8588 - val_accuracy: 0.7887\n",
            "Epoch 135/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7697 - accuracy: 0.7828 - val_loss: 0.8582 - val_accuracy: 0.7875\n",
            "Epoch 136/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7631 - accuracy: 0.7845 - val_loss: 0.8534 - val_accuracy: 0.7906\n",
            "Epoch 137/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7635 - accuracy: 0.7833 - val_loss: 0.8589 - val_accuracy: 0.7883\n",
            "Epoch 138/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7644 - accuracy: 0.7831 - val_loss: 0.8554 - val_accuracy: 0.7874\n",
            "Epoch 139/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7637 - accuracy: 0.7841 - val_loss: 0.8543 - val_accuracy: 0.7907\n",
            "Epoch 140/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7592 - accuracy: 0.7835 - val_loss: 0.8510 - val_accuracy: 0.7917\n",
            "Epoch 141/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7617 - accuracy: 0.7843 - val_loss: 0.8543 - val_accuracy: 0.7893\n",
            "Epoch 142/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7545 - accuracy: 0.7858 - val_loss: 0.8567 - val_accuracy: 0.7888\n",
            "Epoch 143/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7588 - accuracy: 0.7850 - val_loss: 0.8493 - val_accuracy: 0.7903\n",
            "Epoch 144/150\n",
            "127/127 [==============================] - 127s 1s/step - loss: 0.7577 - accuracy: 0.7845 - val_loss: 0.8576 - val_accuracy: 0.7885\n",
            "Epoch 145/150\n",
            "127/127 [==============================] - 128s 1s/step - loss: 0.7535 - accuracy: 0.7867 - val_loss: 0.8505 - val_accuracy: 0.7903\n",
            "Epoch 146/150\n",
            "127/127 [==============================] - 129s 1s/step - loss: 0.7507 - accuracy: 0.7860 - val_loss: 0.8545 - val_accuracy: 0.7905\n",
            "Epoch 147/150\n",
            "127/127 [==============================] - 129s 1s/step - loss: 0.7510 - accuracy: 0.7869 - val_loss: 0.8539 - val_accuracy: 0.7914\n",
            "Epoch 148/150\n",
            "127/127 [==============================] - 129s 1s/step - loss: 0.7495 - accuracy: 0.7857 - val_loss: 0.8481 - val_accuracy: 0.7914\n",
            "Epoch 149/150\n",
            "127/127 [==============================] - 129s 1s/step - loss: 0.7527 - accuracy: 0.7862 - val_loss: 0.8525 - val_accuracy: 0.7895\n",
            "Epoch 150/150\n",
            "127/127 [==============================] - 129s 1s/step - loss: 0.7496 - accuracy: 0.7867 - val_loss: 0.8486 - val_accuracy: 0.7927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGllmK-j5783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "fac1c2cc-c6f7-496c-ba1c-a7498e704643"
      },
      "source": [
        "s, (at, al) = plt.subplots(2,1)\n",
        "at.plot(history.history['accuracy'], c= 'b')\n",
        "at.plot(history.history['val_accuracy'], c='r')\n",
        "at.set_title('model accuracy')\n",
        "at.set_ylabel('accuracy')\n",
        "at.set_xlabel('epoch')\n",
        "at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\n",
        "\n",
        "al.plot(history.history['loss'], c='m')\n",
        "al.plot(history.history['val_loss'], c='c')\n",
        "al.set_title('model loss')\n",
        "al.set_ylabel('loss')\n",
        "al.set_xlabel('epoch')\n",
        "al.legend(['train', 'val'], loc = 'upper left')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5f390bbd50>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unvk7dla6O9V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "76bbcaba-aed3-4837-dba7-d335cb44b8f7"
      },
      "source": [
        "\"\"\"def decode_sentiment(score):\n",
        "    return np.argmax(score) \n",
        "\n",
        "\n",
        "scores = model.predict(x_test, verbose=1, batch_size=10000)\n",
        "y_pred_1d = [decode_sentiment(score) for score in scores]\n",
        "y_pred_1d\"\"\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def decode_sentiment(score):\\n    return np.argmax(score) \\n\\n\\nscores = model.predict(x_test, verbose=1, batch_size=10000)\\ny_pred_1d = [decode_sentiment(score) for score in scores]\\ny_pred_1d'"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B48PqGFw6SDV"
      },
      "source": [
        "\"\"\"import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        " \n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, fontsize=13)\n",
        "    plt.yticks(tick_marks, classes, fontsize=13)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label', fontsize=17)\n",
        "    plt.xlabel('Predicted label', fontsize=17)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXIFb9XK6VCx"
      },
      "source": [
        "\"\"\"cnf_matrix = confusion_matrix(test_data.label.to_list(), y_pred_1d)\n",
        "plt.figure(figsize=(6,6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=test_data.label.unique(), title=\"Confusion matrix\")\n",
        "plt.show()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WO1pq-J6XRH"
      },
      "source": [
        "\"\"\"print(classification_report(list(test_data.label), y_pred_1d))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzEmSWygDqZe"
      },
      "source": [
        "\"\"\"!pip install scikit-plot\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFrW4FEKk9Y"
      },
      "source": [
        "\"\"\"import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    list(test_data.label), \n",
        "    y_pred_1d,\n",
        "    figsize=(12,12),x_tick_rotation=90)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBUj5trlQBNv"
      },
      "source": [
        "\"\"\"y_pred_glove = (model.predict(x_test) > 0.5).astype(\"int\")\"\"\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0-hesTGNzeX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcClMM36Pb25"
      },
      "source": [
        "\"\"\"y_pred = [le.classes_[x] for x in y_pred_glove.argmax(axis=1)]\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoMh---lQcJQ"
      },
      "source": [
        "\"\"\"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "print(\"Accuracy is {} for glove embedding.\".format(accuracy_score(test_data.label, y_pred_glove.argmax(axis=1))))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZBdwIq_QauK"
      },
      "source": [
        "\"\"\"print(classification_report(y_test, y_pred_glove.argmax(axis=1), zero_division = 1))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NQkYXYSY6TR"
      },
      "source": [
        "\"\"\"y_test_probs = model.predict(X_test)\n",
        "\n",
        "# Turn probabilities into an interger prediction\n",
        "y_hat = []\n",
        "for prob in y_test_probs:\n",
        "    y_hat.append(np.argmax(prob))\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
        "print_cf1(y_test, y_hat)\"\"\"\n",
        "\n",
        "\"\"\"print(classification_report(y_test, y_hat, target_names=labels_5))\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}