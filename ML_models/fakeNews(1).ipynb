{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fakeNews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFHRwd5FqLPj",
        "outputId": "691210fb-17de-4da2-9f5e-f9dc03c0a365"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "print(\"Tensorflow Version\",tf.__version__)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Tensorflow Version 2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEkqjihqaXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e37721-308d-403d-d12f-e941aff34fc1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7b_kKv4rRZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8528f552-67c3-4bab-9a5c-772fa3d93ef0"
      },
      "source": [
        "!pip install scikit-learn>=0.24\n",
        "!pip install ktrain # for BERT model"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/dist-packages (0.27.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.96)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: transformers<=4.3.3,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (4.3.3)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.88.0)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain) (5.5.0)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.6.3)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: seqeval==0.0.19 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n",
            "Requirement already satisfied: keras-transformer>=0.39.0 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (0.39.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.12.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.7.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.28.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: keras-self-attention>=0.50.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head>=0.28.0->keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.50.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.8.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.62.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (5.1.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ktrain) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRqq1AHCrdDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1acde95b-7f59-405d-ad69-f26de1313c3b"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/datagram/data/train_datam.csv')\n",
        "df"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>403</td>\n",
              "      <td>Double concentré de tomates MUTTI, tube de 130g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>837</td>\n",
              "      <td>Pur jus de pommes pressées Pure Prémium TROPIC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>485</td>\n",
              "      <td>Rillettes de poulet rôti en cocotte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>363</td>\n",
              "      <td>My Eyes - Taille-crayons 3 diamètres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>591</td>\n",
              "      <td>Brosse à dents Inter Espaces médium AQUAFRESH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161875</th>\n",
              "      <td>162161</td>\n",
              "      <td>372</td>\n",
              "      <td>Lait pour le corps bio à l'aloé véra SO BIO, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161876</th>\n",
              "      <td>162162</td>\n",
              "      <td>510</td>\n",
              "      <td>Hacao aux crevettes + 2 sauces soja, 200g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161877</th>\n",
              "      <td>162163</td>\n",
              "      <td>587</td>\n",
              "      <td>Studio Line - Indestuctible 9, gel fixation ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161878</th>\n",
              "      <td>162164</td>\n",
              "      <td>411</td>\n",
              "      <td>BISCUITS POIREAU 100G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161879</th>\n",
              "      <td>162165</td>\n",
              "      <td>377</td>\n",
              "      <td>Boulettes sauce pour chat au poulet, boîte de ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>161880 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                              pname\n",
              "0                0  ...    Double concentré de tomates MUTTI, tube de 130g\n",
              "1                1  ...  Pur jus de pommes pressées Pure Prémium TROPIC...\n",
              "2                2  ...                Rillettes de poulet rôti en cocotte\n",
              "3                3  ...               My Eyes - Taille-crayons 3 diamètres\n",
              "4                4  ...      Brosse à dents Inter Espaces médium AQUAFRESH\n",
              "...            ...  ...                                                ...\n",
              "161875      162161  ...  Lait pour le corps bio à l'aloé véra SO BIO, 4...\n",
              "161876      162162  ...          Hacao aux crevettes + 2 sauces soja, 200g\n",
              "161877      162163  ...  Studio Line - Indestuctible 9, gel fixation ex...\n",
              "161878      162164  ...                              BISCUITS POIREAU 100G\n",
              "161879      162165  ...  Boulettes sauce pour chat au poulet, boîte de ...\n",
              "\n",
              "[161880 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZCiOCf4reT7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5e55815b-db6a-4710-de57-17371407ca2d"
      },
      "source": [
        "del df['Unnamed: 0']\n",
        "df.columns = ['category_id', 'pname']\n",
        "df.head()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>403</td>\n",
              "      <td>Double concentré de tomates MUTTI, tube de 130g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>837</td>\n",
              "      <td>Pur jus de pommes pressées Pure Prémium TROPIC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>485</td>\n",
              "      <td>Rillettes de poulet rôti en cocotte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>363</td>\n",
              "      <td>My Eyes - Taille-crayons 3 diamètres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>591</td>\n",
              "      <td>Brosse à dents Inter Espaces médium AQUAFRESH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category_id                                              pname\n",
              "0          403    Double concentré de tomates MUTTI, tube de 130g\n",
              "1          837  Pur jus de pommes pressées Pure Prémium TROPIC...\n",
              "2          485                Rillettes de poulet rôti en cocotte\n",
              "3          363               My Eyes - Taille-crayons 3 diamètres\n",
              "4          591      Brosse à dents Inter Espaces médium AQUAFRESH"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epp1uKaDvBB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e9f5f7f8-7bb4-4672-affd-9659740a4ab0"
      },
      "source": [
        "\"\"\"import random\n",
        "random_idx_list = [random.randint(1,len(df.tweet)) for i in range(10)] # creates random indexes to choose from dataframe\n",
        "df.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it\"\"\""
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import random\\nrandom_idx_list = [random.randint(1,len(df.tweet)) for i in range(10)] # creates random indexes to choose from dataframe\\ndf.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it'"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhMZ-NfqvDd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "16f25a5b-8704-41b1-fb13-f1a878c60fc9"
      },
      "source": [
        "\"\"\"stop_words = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\"\""
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stop_words = stopwords.words(\\'english\\')\\nstemmer = SnowballStemmer(\\'english\\')\\n\\ntext_cleaning_re = \"@\\\\S+|https?:\\\\S+|http?:\\\\S|[^A-Za-z0-9]+'"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkzW7tNg2SZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7e3d99b6-7a0b-4864-f6c7-40fbde9a3412"
      },
      "source": [
        "\"\"\"def preprocess(text, stem=False):\n",
        "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    if token not in stop_words:\n",
        "      if stem:\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else:\n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)\"\"\""
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def preprocess(text, stem=False):\\n  text = re.sub(text_cleaning_re, \\' \\', str(text).lower()).strip()\\n  tokens = []\\n  for token in text.split():\\n    if token not in stop_words:\\n      if stem:\\n        tokens.append(stemmer.stem(token))\\n      else:\\n        tokens.append(token)\\n  return \" \".join(tokens)'"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep0PPiU_2WUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b683064-0e2e-40b6-91a0-c6956f05264a"
      },
      "source": [
        "\"\"\"df.tweet = df.tweet.apply(lambda x: preprocess(x))\"\"\""
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'df.tweet = df.tweet.apply(lambda x: preprocess(x))'"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpCLgCQA2bph"
      },
      "source": [
        "TRAIN_SIZE = 0.8\n",
        "MAX_NB_WORDS = 100000\n",
        "MAX_SEQUENCE_LENGTH = 30"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kKVkpLxY2j7"
      },
      "source": [
        "df['tweet'] = df['pname'] \n",
        "df['label'] = df['category_id']  "
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wfEHZlE2dy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773301e0-d5bd-4706-c665-59b0fe1d4304"
      },
      "source": [
        "train_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE,\n",
        "                                         random_state=7) # Splits Dataset into Training and Testing set\n",
        "\n",
        "test_data = test_data.groupby('category_id').filter(lambda x : (x['category_id'].count()>=10).any())\n",
        "train_data = train_data.groupby('category_id').filter(lambda x : (x['category_id'].count()>=10).any())                               \n",
        "print(\"Train Data size:\", len(train_data))\n",
        "print(\"Test Data size\", len(test_data))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data size: 129504\n",
            "Test Data size 32205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLjZamwG2fXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "1d84dec0-5d9c-4f10-c755-b10ba6f7f4df"
      },
      "source": [
        "train_data.head(10)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27381</th>\n",
              "      <td>377</td>\n",
              "      <td>Fines mousses au saumon-poulet-dinde-rognons p...</td>\n",
              "      <td>Fines mousses au saumon-poulet-dinde-rognons p...</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158645</th>\n",
              "      <td>393</td>\n",
              "      <td>Haricots beurre extra-fins d'Aucy, 2x4/4, 880g</td>\n",
              "      <td>Haricots beurre extra-fins d'Aucy, 2x4/4, 880g</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44090</th>\n",
              "      <td>349</td>\n",
              "      <td>Savon détachant écologique à l'huile d'olive b...</td>\n",
              "      <td>Savon détachant écologique à l'huile d'olive b...</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23089</th>\n",
              "      <td>467</td>\n",
              "      <td>*BLEU DES NEIGES 500G</td>\n",
              "      <td>*BLEU DES NEIGES 500G</td>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161552</th>\n",
              "      <td>386</td>\n",
              "      <td>Olives vertes farcies au poivron goût piment</td>\n",
              "      <td>Olives vertes farcies au poivron goût piment</td>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49802</th>\n",
              "      <td>610</td>\n",
              "      <td>Mouchoirs</td>\n",
              "      <td>Mouchoirs</td>\n",
              "      <td>610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11173</th>\n",
              "      <td>526</td>\n",
              "      <td>Tarte au chocolat Pierron 400g</td>\n",
              "      <td>Tarte au chocolat Pierron 400g</td>\n",
              "      <td>526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87452</th>\n",
              "      <td>363</td>\n",
              "      <td>Trousse petit modèle, Ca612 DESSANGE</td>\n",
              "      <td>Trousse petit modèle, Ca612 DESSANGE</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116463</th>\n",
              "      <td>600</td>\n",
              "      <td>Rasoir pour homme sensitive skinguard GILLETTE...</td>\n",
              "      <td>Rasoir pour homme sensitive skinguard GILLETTE...</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102295</th>\n",
              "      <td>597</td>\n",
              "      <td>Gel douche tonifiant NATURA SIBERICA, 400ml</td>\n",
              "      <td>Gel douche tonifiant NATURA SIBERICA, 400ml</td>\n",
              "      <td>597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category_id  ... label\n",
              "27381           377  ...   377\n",
              "158645          393  ...   393\n",
              "44090           349  ...   349\n",
              "23089           467  ...   467\n",
              "161552          386  ...   386\n",
              "49802           610  ...   610\n",
              "11173           526  ...   526\n",
              "87452           363  ...   363\n",
              "116463          600  ...   600\n",
              "102295          597  ...   597\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbKZwRWa2rU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb783e2-69df-4f88-8aef-19a6fbfa499a"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data.tweet)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size : 28867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0cCYC62uAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a18a38-f5ae-4172-9814-d381f9eb74b5"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet),\n",
        "                        maxlen = MAX_SEQUENCE_LENGTH)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet),\n",
        "                       maxlen = MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"Training X Shape:\",x_train.shape)\n",
        "print(\"Testing X Shape:\",x_test.shape)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training X Shape: (129504, 30)\n",
            "Testing X Shape: (32205, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJmhPsoE2xAq"
      },
      "source": [
        "labels = train_data.label.unique().tolist()"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwzmdjMB2zKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89980bed-dd03-4bf3-9562-30d2cc706bcc"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_data.label.to_list())\n",
        "\n",
        "y_train = encoder.transform(train_data.label.to_list())\n",
        "y_test = encoder.transform(test_data.label.to_list())\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (129504, 1)\n",
            "y_test shape: (32205, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpflnyNl20-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3af4ec-7a46-400e-cf70-73513d434a01"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 22:34:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-25 22:34:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-25 22:34:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.2’\n",
            "\n",
            "glove.6B.zip.2      100%[===================>] 822.24M  5.01MB/s    in 2m 40s  \n",
            "\n",
            "2021-09-25 22:37:11 (5.13 MB/s) - ‘glove.6B.zip.2’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       y\n",
            "\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: glove.6B.200d.txt       y\n",
            "y\n",
            "y\n",
            "y\n",
            "\n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: glove.6B.300d.txt       y\n",
            "y\n",
            "n\n",
            "n\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvws1aWI23Aj"
      },
      "source": [
        "GLOVE_EMB = '/content/glove.6B.300d.txt'\n",
        "EMBEDDING_DIM = 300\n",
        "LR = 1e-3\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 150\n",
        "MODEL_PATH = '/content/drive/MyDrive/Classroom/best_model.hdf5'"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M7c5ngg324Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22acfa61-e749-4d84-b57b-0a1f0017d2be"
      },
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open(GLOVE_EMB)\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = value = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2auYeto364c"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4g2k7NH4IEK"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(vocab_size,\n",
        "                                          EMBEDDING_DIM,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                          trainable=False)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_9ti4_4KFX"
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN8xtMhc4NUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5b2649-be54-4823-a91f-3f5abfbeb8df"
      },
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedding_sequences = embedding_layer(sequence_input)\n",
        "x = SpatialDropout1D(0.2)(embedding_sequences)\n",
        "x = Conv1D(64, 5, activation='relu')(x)\n",
        "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(len(labels), activation='sigmoid')(x)\n",
        "model = tf.keras.Model(sequence_input, outputs)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H_fd2sL4Pnv"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1,\n",
        "                                     min_lr = 0.01,\n",
        "                                     monitor = 'val_loss',\n",
        "                                     verbose = 1)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kZWwp0Y4TDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae252dc-c03d-4126-fb80-0d169304297d"
      },
      "source": [
        "print(\"Training on GPU...\") if tf.test.is_gpu_available() else print(\"Training on CPU...\")"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3WHp5M84Xev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14bef890-5047-4060-a7ff-157601ae938f"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "127/127 [==============================] - 63s 452ms/step - loss: 4.1543 - accuracy: 0.1715 - val_loss: 2.5806 - val_accuracy: 0.4147\n",
            "Epoch 2/150\n",
            "127/127 [==============================] - 57s 449ms/step - loss: 2.5162 - accuracy: 0.4265 - val_loss: 1.9311 - val_accuracy: 0.5456\n",
            "Epoch 3/150\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 2.1026 - accuracy: 0.5075 - val_loss: 1.6801 - val_accuracy: 0.5990\n",
            "Epoch 4/150\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.9043 - accuracy: 0.5461 - val_loss: 1.5439 - val_accuracy: 0.6253\n",
            "Epoch 5/150\n",
            "127/127 [==============================] - 56s 444ms/step - loss: 1.7699 - accuracy: 0.5741 - val_loss: 1.4625 - val_accuracy: 0.6438\n",
            "Epoch 6/150\n",
            "127/127 [==============================] - 57s 449ms/step - loss: 1.6726 - accuracy: 0.5923 - val_loss: 1.3976 - val_accuracy: 0.6574\n",
            "Epoch 7/150\n",
            "127/127 [==============================] - 58s 453ms/step - loss: 1.5996 - accuracy: 0.6078 - val_loss: 1.3200 - val_accuracy: 0.6713\n",
            "Epoch 8/150\n",
            "127/127 [==============================] - 58s 454ms/step - loss: 1.5391 - accuracy: 0.6201 - val_loss: 1.2785 - val_accuracy: 0.6851\n",
            "Epoch 9/150\n",
            "127/127 [==============================] - 58s 455ms/step - loss: 1.4885 - accuracy: 0.6313 - val_loss: 1.2512 - val_accuracy: 0.6880\n",
            "Epoch 10/150\n",
            "127/127 [==============================] - 58s 458ms/step - loss: 1.4454 - accuracy: 0.6389 - val_loss: 1.2180 - val_accuracy: 0.6973\n",
            "Epoch 11/150\n",
            "127/127 [==============================] - 58s 453ms/step - loss: 1.4011 - accuracy: 0.6481 - val_loss: 1.1998 - val_accuracy: 0.7020\n",
            "Epoch 12/150\n",
            "127/127 [==============================] - 57s 451ms/step - loss: 1.3737 - accuracy: 0.6543 - val_loss: 1.1723 - val_accuracy: 0.7087\n",
            "Epoch 13/150\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.3453 - accuracy: 0.6602 - val_loss: 1.1546 - val_accuracy: 0.7122\n",
            "Epoch 14/150\n",
            "127/127 [==============================] - 57s 451ms/step - loss: 1.3130 - accuracy: 0.6653 - val_loss: 1.1295 - val_accuracy: 0.7159\n",
            "Epoch 15/150\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 1.2927 - accuracy: 0.6706 - val_loss: 1.1129 - val_accuracy: 0.7208\n",
            "Epoch 16/150\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.2707 - accuracy: 0.6753 - val_loss: 1.1002 - val_accuracy: 0.7253\n",
            "Epoch 17/150\n",
            "127/127 [==============================] - 57s 452ms/step - loss: 1.2502 - accuracy: 0.6790 - val_loss: 1.0975 - val_accuracy: 0.7231\n",
            "Epoch 18/150\n",
            "127/127 [==============================] - 58s 456ms/step - loss: 1.2308 - accuracy: 0.6835 - val_loss: 1.0755 - val_accuracy: 0.7300\n",
            "Epoch 19/150\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 1.2157 - accuracy: 0.6874 - val_loss: 1.0664 - val_accuracy: 0.7310\n",
            "Epoch 20/150\n",
            "127/127 [==============================] - 56s 444ms/step - loss: 1.1995 - accuracy: 0.6895 - val_loss: 1.0577 - val_accuracy: 0.7332\n",
            "Epoch 21/150\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.1842 - accuracy: 0.6926 - val_loss: 1.0422 - val_accuracy: 0.7372\n",
            "Epoch 22/150\n",
            "127/127 [==============================] - 57s 450ms/step - loss: 1.1734 - accuracy: 0.6961 - val_loss: 1.0465 - val_accuracy: 0.7356\n",
            "Epoch 23/150\n",
            "127/127 [==============================] - 57s 450ms/step - loss: 1.1579 - accuracy: 0.6999 - val_loss: 1.0316 - val_accuracy: 0.7378\n",
            "Epoch 24/150\n",
            "127/127 [==============================] - 58s 453ms/step - loss: 1.1427 - accuracy: 0.7015 - val_loss: 1.0267 - val_accuracy: 0.7417\n",
            "Epoch 25/150\n",
            "127/127 [==============================] - 57s 452ms/step - loss: 1.1325 - accuracy: 0.7041 - val_loss: 1.0136 - val_accuracy: 0.7439\n",
            "Epoch 26/150\n",
            "127/127 [==============================] - 57s 450ms/step - loss: 1.1193 - accuracy: 0.7065 - val_loss: 0.9999 - val_accuracy: 0.7472\n",
            "Epoch 27/150\n",
            "127/127 [==============================] - 57s 449ms/step - loss: 1.1065 - accuracy: 0.7111 - val_loss: 1.0055 - val_accuracy: 0.7458\n",
            "Epoch 28/150\n",
            "127/127 [==============================] - 57s 445ms/step - loss: 1.1036 - accuracy: 0.7100 - val_loss: 0.9961 - val_accuracy: 0.7492\n",
            "Epoch 29/150\n",
            "127/127 [==============================] - 57s 448ms/step - loss: 1.0947 - accuracy: 0.7116 - val_loss: 0.9959 - val_accuracy: 0.7483\n",
            "Epoch 30/150\n",
            "127/127 [==============================] - 57s 450ms/step - loss: 1.0839 - accuracy: 0.7134 - val_loss: 0.9929 - val_accuracy: 0.7487\n",
            "Epoch 31/150\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 1.0763 - accuracy: 0.7162 - val_loss: 0.9906 - val_accuracy: 0.7503\n",
            "Epoch 32/150\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.0691 - accuracy: 0.7161 - val_loss: 0.9819 - val_accuracy: 0.7540\n",
            "Epoch 33/150\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.0598 - accuracy: 0.7188 - val_loss: 0.9686 - val_accuracy: 0.7572\n",
            "Epoch 34/150\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.0520 - accuracy: 0.7212 - val_loss: 0.9760 - val_accuracy: 0.7512\n",
            "Epoch 35/150\n",
            "127/127 [==============================] - 56s 444ms/step - loss: 1.0448 - accuracy: 0.7222 - val_loss: 0.9688 - val_accuracy: 0.7573\n",
            "Epoch 36/150\n",
            "127/127 [==============================] - 55s 434ms/step - loss: 1.0378 - accuracy: 0.7244 - val_loss: 0.9571 - val_accuracy: 0.7597\n",
            "Epoch 37/150\n",
            "127/127 [==============================] - 56s 437ms/step - loss: 1.0280 - accuracy: 0.7265 - val_loss: 0.9566 - val_accuracy: 0.7590\n",
            "Epoch 38/150\n",
            "127/127 [==============================] - 56s 437ms/step - loss: 1.0212 - accuracy: 0.7285 - val_loss: 0.9489 - val_accuracy: 0.7606\n",
            "Epoch 39/150\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.0175 - accuracy: 0.7283 - val_loss: 0.9449 - val_accuracy: 0.7617\n",
            "Epoch 40/150\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.0090 - accuracy: 0.7296 - val_loss: 0.9524 - val_accuracy: 0.7601\n",
            "Epoch 41/150\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.0049 - accuracy: 0.7306 - val_loss: 0.9446 - val_accuracy: 0.7620\n",
            "Epoch 42/150\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 0.9977 - accuracy: 0.7317 - val_loss: 0.9387 - val_accuracy: 0.7628\n",
            "Epoch 43/150\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 0.9894 - accuracy: 0.7343 - val_loss: 0.9457 - val_accuracy: 0.7601\n",
            "Epoch 44/150\n",
            "127/127 [==============================] - 56s 445ms/step - loss: 0.9902 - accuracy: 0.7339 - val_loss: 0.9419 - val_accuracy: 0.7606\n",
            "Epoch 45/150\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 0.9795 - accuracy: 0.7364 - val_loss: 0.9378 - val_accuracy: 0.7657\n",
            "Epoch 46/150\n",
            "127/127 [==============================] - 57s 445ms/step - loss: 0.9794 - accuracy: 0.7351 - val_loss: 0.9309 - val_accuracy: 0.7655\n",
            "Epoch 47/150\n",
            "127/127 [==============================] - 55s 436ms/step - loss: 0.9693 - accuracy: 0.7393 - val_loss: 0.9284 - val_accuracy: 0.7664\n",
            "Epoch 48/150\n",
            "127/127 [==============================] - 56s 438ms/step - loss: 0.9674 - accuracy: 0.7398 - val_loss: 0.9321 - val_accuracy: 0.7659\n",
            "Epoch 49/150\n",
            "127/127 [==============================] - 55s 435ms/step - loss: 0.9633 - accuracy: 0.7401 - val_loss: 0.9225 - val_accuracy: 0.7686\n",
            "Epoch 50/150\n",
            "127/127 [==============================] - 55s 434ms/step - loss: 0.9587 - accuracy: 0.7423 - val_loss: 0.9311 - val_accuracy: 0.7646\n",
            "Epoch 51/150\n",
            "127/127 [==============================] - 55s 437ms/step - loss: 0.9543 - accuracy: 0.7412 - val_loss: 0.9247 - val_accuracy: 0.7671\n",
            "Epoch 52/150\n",
            "127/127 [==============================] - 56s 437ms/step - loss: 0.9445 - accuracy: 0.7439 - val_loss: 0.9217 - val_accuracy: 0.7681\n",
            "Epoch 53/150\n",
            "127/127 [==============================] - 55s 433ms/step - loss: 0.9417 - accuracy: 0.7457 - val_loss: 0.9206 - val_accuracy: 0.7684\n",
            "Epoch 54/150\n",
            "127/127 [==============================] - 56s 437ms/step - loss: 0.9382 - accuracy: 0.7463 - val_loss: 0.9228 - val_accuracy: 0.7695\n",
            "Epoch 55/150\n",
            "127/127 [==============================] - 55s 437ms/step - loss: 0.9335 - accuracy: 0.7455 - val_loss: 0.9203 - val_accuracy: 0.7701\n",
            "Epoch 56/150\n",
            "127/127 [==============================] - 55s 433ms/step - loss: 0.9332 - accuracy: 0.7464 - val_loss: 0.9200 - val_accuracy: 0.7697\n",
            "Epoch 57/150\n",
            "127/127 [==============================] - 55s 435ms/step - loss: 0.9285 - accuracy: 0.7482 - val_loss: 0.9177 - val_accuracy: 0.7688\n",
            "Epoch 58/150\n",
            "127/127 [==============================] - 55s 431ms/step - loss: 0.9258 - accuracy: 0.7487 - val_loss: 0.9137 - val_accuracy: 0.7719\n",
            "Epoch 59/150\n",
            "127/127 [==============================] - 55s 430ms/step - loss: 0.9200 - accuracy: 0.7501 - val_loss: 0.9046 - val_accuracy: 0.7718\n",
            "Epoch 60/150\n",
            "127/127 [==============================] - 54s 429ms/step - loss: 0.9141 - accuracy: 0.7506 - val_loss: 0.9075 - val_accuracy: 0.7745\n",
            "Epoch 61/150\n",
            "127/127 [==============================] - 54s 428ms/step - loss: 0.9165 - accuracy: 0.7505 - val_loss: 0.9033 - val_accuracy: 0.7721\n",
            "Epoch 62/150\n",
            "127/127 [==============================] - 55s 436ms/step - loss: 0.9111 - accuracy: 0.7520 - val_loss: 0.9049 - val_accuracy: 0.7727\n",
            "Epoch 63/150\n",
            "127/127 [==============================] - 56s 439ms/step - loss: 0.9053 - accuracy: 0.7530 - val_loss: 0.9047 - val_accuracy: 0.7716\n",
            "Epoch 64/150\n",
            "127/127 [==============================] - 56s 438ms/step - loss: 0.9010 - accuracy: 0.7528 - val_loss: 0.9071 - val_accuracy: 0.7733\n",
            "Epoch 65/150\n",
            "127/127 [==============================] - 55s 436ms/step - loss: 0.9027 - accuracy: 0.7523 - val_loss: 0.9005 - val_accuracy: 0.7734\n",
            "Epoch 66/150\n",
            "127/127 [==============================] - 55s 436ms/step - loss: 0.8988 - accuracy: 0.7541 - val_loss: 0.8969 - val_accuracy: 0.7753\n",
            "Epoch 67/150\n",
            "127/127 [==============================] - 55s 436ms/step - loss: 0.8945 - accuracy: 0.7550 - val_loss: 0.8986 - val_accuracy: 0.7731\n",
            "Epoch 68/150\n",
            "127/127 [==============================] - 55s 436ms/step - loss: 0.8906 - accuracy: 0.7553 - val_loss: 0.9014 - val_accuracy: 0.7735\n",
            "Epoch 69/150\n",
            "127/127 [==============================] - 56s 444ms/step - loss: 0.8900 - accuracy: 0.7552 - val_loss: 0.8982 - val_accuracy: 0.7742\n",
            "Epoch 70/150\n",
            "127/127 [==============================] - 57s 448ms/step - loss: 0.8829 - accuracy: 0.7578 - val_loss: 0.8968 - val_accuracy: 0.7774\n",
            "Epoch 71/150\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 0.8821 - accuracy: 0.7571 - val_loss: 0.8940 - val_accuracy: 0.7786\n",
            "Epoch 72/150\n",
            "127/127 [==============================] - 56s 441ms/step - loss: 0.8798 - accuracy: 0.7578 - val_loss: 0.8863 - val_accuracy: 0.7790\n",
            "Epoch 73/150\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 0.8778 - accuracy: 0.7574 - val_loss: 0.8878 - val_accuracy: 0.7794\n",
            "Epoch 74/150\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 0.8747 - accuracy: 0.7594 - val_loss: 0.8881 - val_accuracy: 0.7776\n",
            "Epoch 75/150\n",
            "127/127 [==============================] - 55s 436ms/step - loss: 0.8771 - accuracy: 0.7579 - val_loss: 0.8918 - val_accuracy: 0.7779\n",
            "Epoch 76/150\n",
            "127/127 [==============================] - 56s 438ms/step - loss: 0.8687 - accuracy: 0.7607 - val_loss: 0.8879 - val_accuracy: 0.7776\n",
            "Epoch 77/150\n",
            "127/127 [==============================] - 55s 435ms/step - loss: 0.8636 - accuracy: 0.7618 - val_loss: 0.8902 - val_accuracy: 0.7783\n",
            "Epoch 78/150\n",
            "  8/127 [>.............................] - ETA: 50s - loss: 0.8348 - accuracy: 0.7664"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGllmK-j5783"
      },
      "source": [
        "s, (at, al) = plt.subplots(2,1)\n",
        "at.plot(history.history['accuracy'], c= 'b')\n",
        "at.plot(history.history['val_accuracy'], c='r')\n",
        "at.set_title('model accuracy')\n",
        "at.set_ylabel('accuracy')\n",
        "at.set_xlabel('epoch')\n",
        "at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\n",
        "\n",
        "al.plot(history.history['loss'], c='m')\n",
        "al.plot(history.history['val_loss'], c='c')\n",
        "al.set_title('model loss')\n",
        "al.set_ylabel('loss')\n",
        "al.set_xlabel('epoch')\n",
        "al.legend(['train', 'val'], loc = 'upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unvk7dla6O9V"
      },
      "source": [
        "\"\"\"def decode_sentiment(score):\n",
        "    return np.argmax(score) \n",
        "\n",
        "\n",
        "scores = model.predict(x_test, verbose=1, batch_size=10000)\n",
        "y_pred_1d = [decode_sentiment(score) for score in scores]\n",
        "y_pred_1d\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B48PqGFw6SDV"
      },
      "source": [
        "\"\"\"import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    \"\"\"This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, fontsize=13)\n",
        "    plt.yticks(tick_marks, classes, fontsize=13)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label', fontsize=17)\n",
        "    plt.xlabel('Predicted label', fontsize=17)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXIFb9XK6VCx"
      },
      "source": [
        "\"\"\"cnf_matrix = confusion_matrix(test_data.label.to_list(), y_pred_1d)\n",
        "plt.figure(figsize=(6,6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=test_data.label.unique(), title=\"Confusion matrix\")\n",
        "plt.show()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WO1pq-J6XRH"
      },
      "source": [
        "\"\"\"print(classification_report(list(test_data.label), y_pred_1d))\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzEmSWygDqZe"
      },
      "source": [
        "\"\"\"!pip install scikit-plot\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFrW4FEKk9Y"
      },
      "source": [
        "\"\"\"import scikitplot as skplt\n",
        "\n",
        "skplt.metrics.plot_confusion_matrix(\n",
        "    list(test_data.label), \n",
        "    y_pred_1d,\n",
        "    figsize=(12,12),x_tick_rotation=90)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBUj5trlQBNv"
      },
      "source": [
        "y_pred_glove = (model.predict(x_test) > 0.5).astype(\"int\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoMh---lQcJQ"
      },
      "source": [
        "print(\"Accuracy is {} for glove embedding.\".format(accuracy_score(test_data.label, y_pred_glove)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZBdwIq_QauK"
      },
      "source": [
        "print(classification_report(y_test, y_pred_glove, zero_division = 1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}