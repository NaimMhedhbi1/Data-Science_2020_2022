{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fakeNews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFHRwd5FqLPj",
        "outputId": "2d61769a-5259-41dd-a20d-901438e87f5e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "print(\"Tensorflow Version\",tf.__version__)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Tensorflow Version 2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEkqjihqaXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a406667-bfad-46c6-d092-979aeed914ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7b_kKv4rRZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93c326a-930e-41af-9c69-988b3952f495"
      },
      "source": [
        "!pip install scikit-learn>=0.24\n",
        "!pip install ktrain # for BERT model"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/dist-packages (0.27.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.96)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.88.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Requirement already satisfied: transformers<=4.3.3,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (4.3.3)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.6.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain) (5.5.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: seqeval==0.0.19 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (2.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n",
            "Requirement already satisfied: keras-transformer>=0.39.0 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (0.39.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.7.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.12.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.28.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: keras-self-attention>=0.50.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head>=0.28.0->keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.50.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.62.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain) (3.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (5.1.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ktrain) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRqq1AHCrdDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3bcc4233-cf4c-4199-af65-b0c388a0c884"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/datagram/data/train_datam.csv')\n",
        "df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>403</td>\n",
              "      <td>Double concentré de tomates MUTTI, tube de 130g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>837</td>\n",
              "      <td>Pur jus de pommes pressées Pure Prémium TROPIC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>485</td>\n",
              "      <td>Rillettes de poulet rôti en cocotte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>363</td>\n",
              "      <td>My Eyes - Taille-crayons 3 diamètres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>591</td>\n",
              "      <td>Brosse à dents Inter Espaces médium AQUAFRESH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161875</th>\n",
              "      <td>162161</td>\n",
              "      <td>372</td>\n",
              "      <td>Lait pour le corps bio à l'aloé véra SO BIO, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161876</th>\n",
              "      <td>162162</td>\n",
              "      <td>510</td>\n",
              "      <td>Hacao aux crevettes + 2 sauces soja, 200g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161877</th>\n",
              "      <td>162163</td>\n",
              "      <td>587</td>\n",
              "      <td>Studio Line - Indestuctible 9, gel fixation ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161878</th>\n",
              "      <td>162164</td>\n",
              "      <td>411</td>\n",
              "      <td>BISCUITS POIREAU 100G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161879</th>\n",
              "      <td>162165</td>\n",
              "      <td>377</td>\n",
              "      <td>Boulettes sauce pour chat au poulet, boîte de ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>161880 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ...                                              pname\n",
              "0                0  ...    Double concentré de tomates MUTTI, tube de 130g\n",
              "1                1  ...  Pur jus de pommes pressées Pure Prémium TROPIC...\n",
              "2                2  ...                Rillettes de poulet rôti en cocotte\n",
              "3                3  ...               My Eyes - Taille-crayons 3 diamètres\n",
              "4                4  ...      Brosse à dents Inter Espaces médium AQUAFRESH\n",
              "...            ...  ...                                                ...\n",
              "161875      162161  ...  Lait pour le corps bio à l'aloé véra SO BIO, 4...\n",
              "161876      162162  ...          Hacao aux crevettes + 2 sauces soja, 200g\n",
              "161877      162163  ...  Studio Line - Indestuctible 9, gel fixation ex...\n",
              "161878      162164  ...                              BISCUITS POIREAU 100G\n",
              "161879      162165  ...  Boulettes sauce pour chat au poulet, boîte de ...\n",
              "\n",
              "[161880 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZCiOCf4reT7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a34dd044-d23b-4f0a-9cc3-4a37d0085371"
      },
      "source": [
        "del df['Unnamed: 0']\n",
        "df.columns = ['category_id', 'pname']\n",
        "df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>403</td>\n",
              "      <td>Double concentré de tomates MUTTI, tube de 130g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>837</td>\n",
              "      <td>Pur jus de pommes pressées Pure Prémium TROPIC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>485</td>\n",
              "      <td>Rillettes de poulet rôti en cocotte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>363</td>\n",
              "      <td>My Eyes - Taille-crayons 3 diamètres</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>591</td>\n",
              "      <td>Brosse à dents Inter Espaces médium AQUAFRESH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category_id                                              pname\n",
              "0          403    Double concentré de tomates MUTTI, tube de 130g\n",
              "1          837  Pur jus de pommes pressées Pure Prémium TROPIC...\n",
              "2          485                Rillettes de poulet rôti en cocotte\n",
              "3          363               My Eyes - Taille-crayons 3 diamètres\n",
              "4          591      Brosse à dents Inter Espaces médium AQUAFRESH"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epp1uKaDvBB9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "837d3606-c4ff-44a9-b650-615b35a95e51"
      },
      "source": [
        "\"\"\"import random\n",
        "random_idx_list = [random.randint(1,len(df.tweet)) for i in range(10)] # creates random indexes to choose from dataframe\n",
        "df.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it\"\"\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import random\\nrandom_idx_list = [random.randint(1,len(df.tweet)) for i in range(10)] # creates random indexes to choose from dataframe\\ndf.loc[random_idx_list,:].head(10) # Returns the rows with the index and display it'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhMZ-NfqvDd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f4415c92-2280-458b-c110-f4936f7d056a"
      },
      "source": [
        "\"\"\"stop_words = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\"\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stop_words = stopwords.words(\\'english\\')\\nstemmer = SnowballStemmer(\\'english\\')\\n\\ntext_cleaning_re = \"@\\\\S+|https?:\\\\S+|http?:\\\\S|[^A-Za-z0-9]+'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkzW7tNg2SZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "89ab0e6a-b00d-4bf3-e4a6-b96a5a2d2257"
      },
      "source": [
        "\"\"\"def preprocess(text, stem=False):\n",
        "  text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    if token not in stop_words:\n",
        "      if stem:\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else:\n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)\"\"\""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def preprocess(text, stem=False):\\n  text = re.sub(text_cleaning_re, \\' \\', str(text).lower()).strip()\\n  tokens = []\\n  for token in text.split():\\n    if token not in stop_words:\\n      if stem:\\n        tokens.append(stemmer.stem(token))\\n      else:\\n        tokens.append(token)\\n  return \" \".join(tokens)'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep0PPiU_2WUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b261bc09-767b-4ea2-a734-113f1dfb1db4"
      },
      "source": [
        "\"\"\"df.tweet = df.tweet.apply(lambda x: preprocess(x))\"\"\""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'df.tweet = df.tweet.apply(lambda x: preprocess(x))'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpCLgCQA2bph"
      },
      "source": [
        "TRAIN_SIZE = 0.8\n",
        "MAX_NB_WORDS = 100000\n",
        "MAX_SEQUENCE_LENGTH = 30"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kKVkpLxY2j7"
      },
      "source": [
        "df['tweet'] = df['pname'] \n",
        "df['label'] = df['category_id']  "
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wfEHZlE2dy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0567ba-6f70-49d9-ee5d-e4bb2e97ef37"
      },
      "source": [
        "train_data, test_data = train_test_split(df, test_size=1-TRAIN_SIZE,\n",
        "                                         random_state=7) # Splits Dataset into Training and Testing set\n",
        "\n",
        "test_data = test_data.groupby('category_id').filter(lambda x : (x['category_id'].count()>=10).any())\n",
        "train_data = train_data.groupby('category_id').filter(lambda x : (x['category_id'].count()>=10).any())                               \n",
        "print(\"Train Data size:\", len(train_data))\n",
        "print(\"Test Data size\", len(test_data))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data size: 129504\n",
            "Test Data size 32205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLjZamwG2fXx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "0a23660b-6fe8-4986-e734-7cea3663889b"
      },
      "source": [
        "train_data.head(10)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>pname</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27381</th>\n",
              "      <td>377</td>\n",
              "      <td>Fines mousses au saumon-poulet-dinde-rognons p...</td>\n",
              "      <td>Fines mousses au saumon-poulet-dinde-rognons p...</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158645</th>\n",
              "      <td>393</td>\n",
              "      <td>Haricots beurre extra-fins d'Aucy, 2x4/4, 880g</td>\n",
              "      <td>Haricots beurre extra-fins d'Aucy, 2x4/4, 880g</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44090</th>\n",
              "      <td>349</td>\n",
              "      <td>Savon détachant écologique à l'huile d'olive b...</td>\n",
              "      <td>Savon détachant écologique à l'huile d'olive b...</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23089</th>\n",
              "      <td>467</td>\n",
              "      <td>*BLEU DES NEIGES 500G</td>\n",
              "      <td>*BLEU DES NEIGES 500G</td>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161552</th>\n",
              "      <td>386</td>\n",
              "      <td>Olives vertes farcies au poivron goût piment</td>\n",
              "      <td>Olives vertes farcies au poivron goût piment</td>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49802</th>\n",
              "      <td>610</td>\n",
              "      <td>Mouchoirs</td>\n",
              "      <td>Mouchoirs</td>\n",
              "      <td>610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11173</th>\n",
              "      <td>526</td>\n",
              "      <td>Tarte au chocolat Pierron 400g</td>\n",
              "      <td>Tarte au chocolat Pierron 400g</td>\n",
              "      <td>526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87452</th>\n",
              "      <td>363</td>\n",
              "      <td>Trousse petit modèle, Ca612 DESSANGE</td>\n",
              "      <td>Trousse petit modèle, Ca612 DESSANGE</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116463</th>\n",
              "      <td>600</td>\n",
              "      <td>Rasoir pour homme sensitive skinguard GILLETTE...</td>\n",
              "      <td>Rasoir pour homme sensitive skinguard GILLETTE...</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102295</th>\n",
              "      <td>597</td>\n",
              "      <td>Gel douche tonifiant NATURA SIBERICA, 400ml</td>\n",
              "      <td>Gel douche tonifiant NATURA SIBERICA, 400ml</td>\n",
              "      <td>597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category_id  ... label\n",
              "27381           377  ...   377\n",
              "158645          393  ...   393\n",
              "44090           349  ...   349\n",
              "23089           467  ...   467\n",
              "161552          386  ...   386\n",
              "49802           610  ...   610\n",
              "11173           526  ...   526\n",
              "87452           363  ...   363\n",
              "116463          600  ...   600\n",
              "102295          597  ...   597\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbKZwRWa2rU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0cdb7a-6335-4155-90ea-d1cf7a9eb5bd"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data.tweet)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size : 28867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF0cCYC62uAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7a0f13-0200-4ce6-c98f-28210554ac47"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet),\n",
        "                        maxlen = MAX_SEQUENCE_LENGTH)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet),\n",
        "                       maxlen = MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"Training X Shape:\",x_train.shape)\n",
        "print(\"Testing X Shape:\",x_test.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training X Shape: (129504, 30)\n",
            "Testing X Shape: (32205, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJmhPsoE2xAq"
      },
      "source": [
        "labels = train_data.label.unique().tolist()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwzmdjMB2zKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1fdc20-72f7-4050-f582-5096359d12e5"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_data.label.to_list())\n",
        "\n",
        "y_train = encoder.transform(train_data.label.to_list())\n",
        "y_test = encoder.transform(test_data.label.to_list())\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (129504, 1)\n",
            "y_test shape: (32205, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpflnyNl20-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92778e71-42c6-4011-c1a7-1a5a3f5ac540"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 19:21:41--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-25 19:21:42--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-25 19:21:42--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.38MB/s    in 2m 46s  \n",
            "\n",
            "2021-09-25 19:24:28 (4.95 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       \n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.200d.txt       y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvws1aWI23Aj"
      },
      "source": [
        "GLOVE_EMB = '/content/glove.6B.300d.txt'\n",
        "EMBEDDING_DIM = 300\n",
        "LR = 1e-3\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 100\n",
        "MODEL_PATH = '/content/drive/MyDrive/Classroom/best_model.hdf5'"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M7c5ngg324Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e366c066-e7e0-4ad0-fa94-1d4b2aa130b5"
      },
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open(GLOVE_EMB)\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = value = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2auYeto364c"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4g2k7NH4IEK"
      },
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(vocab_size,\n",
        "                                          EMBEDDING_DIM,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                          trainable=False)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_9ti4_4KFX"
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN8xtMhc4NUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5611785d-72b7-426b-baf7-b86ede0a39a5"
      },
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedding_sequences = embedding_layer(sequence_input)\n",
        "x = SpatialDropout1D(0.2)(embedding_sequences)\n",
        "x = Conv1D(64, 5, activation='relu')(x)\n",
        "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(len(labels), activation='sigmoid')(x)\n",
        "model = tf.keras.Model(sequence_input, outputs)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H_fd2sL4Pnv"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1,\n",
        "                                     min_lr = 0.01,\n",
        "                                     monitor = 'val_loss',\n",
        "                                     verbose = 1)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kZWwp0Y4TDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44568678-83aa-40e5-aeab-20d26d88e432"
      },
      "source": [
        "print(\"Training on GPU...\") if tf.test.is_gpu_available() else print(\"Training on CPU...\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3WHp5M84Xev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dea47ac-6808-4d08-aa44-8726cb9f5120"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "127/127 [==============================] - 63s 450ms/step - loss: 4.1359 - accuracy: 0.1769 - val_loss: 2.6581 - val_accuracy: 0.4081\n",
            "Epoch 2/100\n",
            "127/127 [==============================] - 57s 448ms/step - loss: 2.5715 - accuracy: 0.4166 - val_loss: 2.0043 - val_accuracy: 0.5308\n",
            "Epoch 3/100\n",
            "127/127 [==============================] - 56s 440ms/step - loss: 2.1415 - accuracy: 0.4987 - val_loss: 1.7144 - val_accuracy: 0.5924\n",
            "Epoch 4/100\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.9221 - accuracy: 0.5431 - val_loss: 1.5663 - val_accuracy: 0.6221\n",
            "Epoch 5/100\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.7837 - accuracy: 0.5709 - val_loss: 1.4633 - val_accuracy: 0.6438\n",
            "Epoch 6/100\n",
            "127/127 [==============================] - 57s 445ms/step - loss: 1.6840 - accuracy: 0.5911 - val_loss: 1.3829 - val_accuracy: 0.6641\n",
            "Epoch 7/100\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.6090 - accuracy: 0.6067 - val_loss: 1.3279 - val_accuracy: 0.6755\n",
            "Epoch 8/100\n",
            "127/127 [==============================] - 56s 445ms/step - loss: 1.5462 - accuracy: 0.6185 - val_loss: 1.2864 - val_accuracy: 0.6846\n",
            "Epoch 9/100\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.4949 - accuracy: 0.6289 - val_loss: 1.2602 - val_accuracy: 0.6886\n",
            "Epoch 10/100\n",
            "127/127 [==============================] - 56s 441ms/step - loss: 1.4500 - accuracy: 0.6403 - val_loss: 1.2245 - val_accuracy: 0.6935\n",
            "Epoch 11/100\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.4117 - accuracy: 0.6458 - val_loss: 1.1997 - val_accuracy: 0.7016\n",
            "Epoch 12/100\n",
            "127/127 [==============================] - 57s 452ms/step - loss: 1.3811 - accuracy: 0.6541 - val_loss: 1.1728 - val_accuracy: 0.7076\n",
            "Epoch 13/100\n",
            "127/127 [==============================] - 56s 441ms/step - loss: 1.3488 - accuracy: 0.6581 - val_loss: 1.1504 - val_accuracy: 0.7138\n",
            "Epoch 14/100\n",
            "127/127 [==============================] - 57s 450ms/step - loss: 1.3210 - accuracy: 0.6649 - val_loss: 1.1295 - val_accuracy: 0.7196\n",
            "Epoch 15/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.3040 - accuracy: 0.6700 - val_loss: 1.1153 - val_accuracy: 0.7226\n",
            "Epoch 16/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.2787 - accuracy: 0.6735 - val_loss: 1.1134 - val_accuracy: 0.7209\n",
            "Epoch 17/100\n",
            "127/127 [==============================] - 58s 454ms/step - loss: 1.2576 - accuracy: 0.6773 - val_loss: 1.0952 - val_accuracy: 0.7281\n",
            "Epoch 18/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.2405 - accuracy: 0.6822 - val_loss: 1.0802 - val_accuracy: 0.7298\n",
            "Epoch 19/100\n",
            "127/127 [==============================] - 57s 451ms/step - loss: 1.2215 - accuracy: 0.6856 - val_loss: 1.0737 - val_accuracy: 0.7321\n",
            "Epoch 20/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.2041 - accuracy: 0.6901 - val_loss: 1.0635 - val_accuracy: 0.7338\n",
            "Epoch 21/100\n",
            "127/127 [==============================] - 57s 445ms/step - loss: 1.1861 - accuracy: 0.6929 - val_loss: 1.0534 - val_accuracy: 0.7367\n",
            "Epoch 22/100\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.1723 - accuracy: 0.6966 - val_loss: 1.0508 - val_accuracy: 0.7353\n",
            "Epoch 23/100\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 1.1643 - accuracy: 0.6968 - val_loss: 1.0395 - val_accuracy: 0.7393\n",
            "Epoch 24/100\n",
            "127/127 [==============================] - 57s 450ms/step - loss: 1.1507 - accuracy: 0.6998 - val_loss: 1.0314 - val_accuracy: 0.7401\n",
            "Epoch 25/100\n",
            "127/127 [==============================] - 57s 453ms/step - loss: 1.1395 - accuracy: 0.7036 - val_loss: 1.0265 - val_accuracy: 0.7424\n",
            "Epoch 26/100\n",
            "127/127 [==============================] - 57s 448ms/step - loss: 1.1245 - accuracy: 0.7072 - val_loss: 1.0195 - val_accuracy: 0.7443\n",
            "Epoch 27/100\n",
            "127/127 [==============================] - 56s 441ms/step - loss: 1.1193 - accuracy: 0.7060 - val_loss: 1.0023 - val_accuracy: 0.7481\n",
            "Epoch 28/100\n",
            "127/127 [==============================] - 56s 445ms/step - loss: 1.1055 - accuracy: 0.7086 - val_loss: 0.9996 - val_accuracy: 0.7477\n",
            "Epoch 29/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.0967 - accuracy: 0.7127 - val_loss: 0.9982 - val_accuracy: 0.7488\n",
            "Epoch 30/100\n",
            "127/127 [==============================] - 56s 439ms/step - loss: 1.0883 - accuracy: 0.7139 - val_loss: 0.9871 - val_accuracy: 0.7530\n",
            "Epoch 31/100\n",
            "127/127 [==============================] - 56s 439ms/step - loss: 1.0762 - accuracy: 0.7156 - val_loss: 0.9821 - val_accuracy: 0.7541\n",
            "Epoch 32/100\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 1.0704 - accuracy: 0.7180 - val_loss: 0.9833 - val_accuracy: 0.7524\n",
            "Epoch 33/100\n",
            "127/127 [==============================] - 56s 438ms/step - loss: 1.0614 - accuracy: 0.7196 - val_loss: 0.9788 - val_accuracy: 0.7531\n",
            "Epoch 34/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.0536 - accuracy: 0.7201 - val_loss: 0.9695 - val_accuracy: 0.7562\n",
            "Epoch 35/100\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.0492 - accuracy: 0.7225 - val_loss: 0.9736 - val_accuracy: 0.7532\n",
            "Epoch 36/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 1.0402 - accuracy: 0.7227 - val_loss: 0.9629 - val_accuracy: 0.7597\n",
            "Epoch 37/100\n",
            "127/127 [==============================] - 56s 442ms/step - loss: 1.0335 - accuracy: 0.7254 - val_loss: 0.9652 - val_accuracy: 0.7551\n",
            "Epoch 38/100\n",
            "127/127 [==============================] - 56s 444ms/step - loss: 1.0242 - accuracy: 0.7274 - val_loss: 0.9671 - val_accuracy: 0.7569\n",
            "Epoch 39/100\n",
            "127/127 [==============================] - 58s 454ms/step - loss: 1.0173 - accuracy: 0.7289 - val_loss: 0.9524 - val_accuracy: 0.7594\n",
            "Epoch 40/100\n",
            "127/127 [==============================] - 59s 461ms/step - loss: 1.0135 - accuracy: 0.7305 - val_loss: 0.9466 - val_accuracy: 0.7612\n",
            "Epoch 41/100\n",
            "127/127 [==============================] - 59s 461ms/step - loss: 1.0067 - accuracy: 0.7294 - val_loss: 0.9463 - val_accuracy: 0.7609\n",
            "Epoch 42/100\n",
            "127/127 [==============================] - 58s 456ms/step - loss: 1.0017 - accuracy: 0.7320 - val_loss: 0.9438 - val_accuracy: 0.7614\n",
            "Epoch 43/100\n",
            "127/127 [==============================] - 58s 454ms/step - loss: 0.9975 - accuracy: 0.7322 - val_loss: 0.9417 - val_accuracy: 0.7635\n",
            "Epoch 44/100\n",
            "127/127 [==============================] - 58s 454ms/step - loss: 0.9890 - accuracy: 0.7344 - val_loss: 0.9453 - val_accuracy: 0.7600\n",
            "Epoch 45/100\n",
            "127/127 [==============================] - 58s 460ms/step - loss: 0.9820 - accuracy: 0.7361 - val_loss: 0.9378 - val_accuracy: 0.7633\n",
            "Epoch 46/100\n",
            "127/127 [==============================] - 59s 464ms/step - loss: 0.9754 - accuracy: 0.7367 - val_loss: 0.9320 - val_accuracy: 0.7671\n",
            "Epoch 47/100\n",
            "127/127 [==============================] - 59s 462ms/step - loss: 0.9758 - accuracy: 0.7378 - val_loss: 0.9328 - val_accuracy: 0.7662\n",
            "Epoch 48/100\n",
            "127/127 [==============================] - 59s 465ms/step - loss: 0.9680 - accuracy: 0.7382 - val_loss: 0.9283 - val_accuracy: 0.7668\n",
            "Epoch 49/100\n",
            "127/127 [==============================] - 59s 461ms/step - loss: 0.9617 - accuracy: 0.7393 - val_loss: 0.9224 - val_accuracy: 0.7678\n",
            "Epoch 50/100\n",
            "127/127 [==============================] - 59s 465ms/step - loss: 0.9648 - accuracy: 0.7393 - val_loss: 0.9228 - val_accuracy: 0.7668\n",
            "Epoch 51/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 0.9577 - accuracy: 0.7409 - val_loss: 0.9216 - val_accuracy: 0.7690\n",
            "Epoch 52/100\n",
            "127/127 [==============================] - 58s 456ms/step - loss: 0.9516 - accuracy: 0.7415 - val_loss: 0.9246 - val_accuracy: 0.7670\n",
            "Epoch 53/100\n",
            "127/127 [==============================] - 59s 463ms/step - loss: 0.9462 - accuracy: 0.7444 - val_loss: 0.9214 - val_accuracy: 0.7688\n",
            "Epoch 54/100\n",
            "127/127 [==============================] - 58s 459ms/step - loss: 0.9394 - accuracy: 0.7447 - val_loss: 0.9190 - val_accuracy: 0.7682\n",
            "Epoch 55/100\n",
            "127/127 [==============================] - 59s 464ms/step - loss: 0.9370 - accuracy: 0.7454 - val_loss: 0.9139 - val_accuracy: 0.7707\n",
            "Epoch 56/100\n",
            "127/127 [==============================] - 59s 467ms/step - loss: 0.9321 - accuracy: 0.7465 - val_loss: 0.9089 - val_accuracy: 0.7722\n",
            "Epoch 57/100\n",
            "127/127 [==============================] - 59s 463ms/step - loss: 0.9269 - accuracy: 0.7478 - val_loss: 0.9080 - val_accuracy: 0.7735\n",
            "Epoch 58/100\n",
            "127/127 [==============================] - 59s 464ms/step - loss: 0.9267 - accuracy: 0.7487 - val_loss: 0.9082 - val_accuracy: 0.7735\n",
            "Epoch 59/100\n",
            "127/127 [==============================] - 59s 463ms/step - loss: 0.9249 - accuracy: 0.7488 - val_loss: 0.9115 - val_accuracy: 0.7716\n",
            "Epoch 60/100\n",
            "127/127 [==============================] - 58s 460ms/step - loss: 0.9205 - accuracy: 0.7494 - val_loss: 0.9043 - val_accuracy: 0.7732\n",
            "Epoch 61/100\n",
            "127/127 [==============================] - 58s 459ms/step - loss: 0.9207 - accuracy: 0.7482 - val_loss: 0.9034 - val_accuracy: 0.7718\n",
            "Epoch 62/100\n",
            "127/127 [==============================] - 59s 465ms/step - loss: 0.9135 - accuracy: 0.7513 - val_loss: 0.9059 - val_accuracy: 0.7744\n",
            "Epoch 63/100\n",
            "127/127 [==============================] - 58s 459ms/step - loss: 0.9094 - accuracy: 0.7506 - val_loss: 0.9006 - val_accuracy: 0.7745\n",
            "Epoch 64/100\n",
            "127/127 [==============================] - 58s 456ms/step - loss: 0.9058 - accuracy: 0.7510 - val_loss: 0.9055 - val_accuracy: 0.7719\n",
            "Epoch 65/100\n",
            "127/127 [==============================] - 57s 447ms/step - loss: 0.9032 - accuracy: 0.7524 - val_loss: 0.9020 - val_accuracy: 0.7740\n",
            "Epoch 66/100\n",
            "127/127 [==============================] - 57s 445ms/step - loss: 0.9005 - accuracy: 0.7532 - val_loss: 0.8976 - val_accuracy: 0.7766\n",
            "Epoch 67/100\n",
            "127/127 [==============================] - 56s 445ms/step - loss: 0.8936 - accuracy: 0.7562 - val_loss: 0.9017 - val_accuracy: 0.7749\n",
            "Epoch 68/100\n",
            "127/127 [==============================] - 59s 465ms/step - loss: 0.8954 - accuracy: 0.7551 - val_loss: 0.8973 - val_accuracy: 0.7751\n",
            "Epoch 69/100\n",
            "127/127 [==============================] - 59s 466ms/step - loss: 0.8909 - accuracy: 0.7553 - val_loss: 0.8928 - val_accuracy: 0.7770\n",
            "Epoch 70/100\n",
            "127/127 [==============================] - 59s 463ms/step - loss: 0.8865 - accuracy: 0.7555 - val_loss: 0.8891 - val_accuracy: 0.7795\n",
            "Epoch 71/100\n",
            "127/127 [==============================] - 58s 457ms/step - loss: 0.8837 - accuracy: 0.7566 - val_loss: 0.8954 - val_accuracy: 0.7775\n",
            "Epoch 72/100\n",
            "127/127 [==============================] - 59s 464ms/step - loss: 0.8824 - accuracy: 0.7573 - val_loss: 0.8961 - val_accuracy: 0.7760\n",
            "Epoch 73/100\n",
            "127/127 [==============================] - 57s 446ms/step - loss: 0.8736 - accuracy: 0.7589 - val_loss: 0.8877 - val_accuracy: 0.7771\n",
            "Epoch 74/100\n",
            "127/127 [==============================] - 56s 437ms/step - loss: 0.8775 - accuracy: 0.7590 - val_loss: 0.8903 - val_accuracy: 0.7782\n",
            "Epoch 75/100\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 0.8740 - accuracy: 0.7600 - val_loss: 0.8896 - val_accuracy: 0.7787\n",
            "Epoch 76/100\n",
            "127/127 [==============================] - 56s 445ms/step - loss: 0.8733 - accuracy: 0.7597 - val_loss: 0.8815 - val_accuracy: 0.7812\n",
            "Epoch 77/100\n",
            "127/127 [==============================] - 56s 443ms/step - loss: 0.8671 - accuracy: 0.7597 - val_loss: 0.8787 - val_accuracy: 0.7808\n",
            "Epoch 78/100\n",
            "127/127 [==============================] - 57s 448ms/step - loss: 0.8677 - accuracy: 0.7608 - val_loss: 0.8903 - val_accuracy: 0.7796\n",
            "Epoch 79/100\n",
            "127/127 [==============================] - 57s 445ms/step - loss: 0.8605 - accuracy: 0.7613 - val_loss: 0.8880 - val_accuracy: 0.7786\n",
            "Epoch 80/100\n",
            "127/127 [==============================] - 56s 445ms/step - loss: 0.8612 - accuracy: 0.7617 - val_loss: 0.8780 - val_accuracy: 0.7827\n",
            "Epoch 81/100\n",
            "127/127 [==============================] - 59s 462ms/step - loss: 0.8584 - accuracy: 0.7627 - val_loss: 0.8849 - val_accuracy: 0.7808\n",
            "Epoch 82/100\n",
            "127/127 [==============================] - 58s 456ms/step - loss: 0.8549 - accuracy: 0.7638 - val_loss: 0.8814 - val_accuracy: 0.7798\n",
            "Epoch 83/100\n",
            "127/127 [==============================] - 59s 463ms/step - loss: 0.8547 - accuracy: 0.7629 - val_loss: 0.8824 - val_accuracy: 0.7806\n",
            "Epoch 84/100\n",
            "127/127 [==============================] - 58s 457ms/step - loss: 0.8527 - accuracy: 0.7642 - val_loss: 0.8867 - val_accuracy: 0.7808\n",
            "Epoch 85/100\n",
            "127/127 [==============================] - 59s 464ms/step - loss: 0.8463 - accuracy: 0.7655 - val_loss: 0.8796 - val_accuracy: 0.7837\n",
            "Epoch 86/100\n",
            "127/127 [==============================] - 60s 469ms/step - loss: 0.8487 - accuracy: 0.7641 - val_loss: 0.8808 - val_accuracy: 0.7830\n",
            "Epoch 87/100\n",
            "127/127 [==============================] - 58s 459ms/step - loss: 0.8410 - accuracy: 0.7660 - val_loss: 0.8783 - val_accuracy: 0.7823\n",
            "Epoch 88/100\n",
            "127/127 [==============================] - 59s 463ms/step - loss: 0.8420 - accuracy: 0.7661 - val_loss: 0.8727 - val_accuracy: 0.7828\n",
            "Epoch 89/100\n",
            "127/127 [==============================] - 59s 462ms/step - loss: 0.8373 - accuracy: 0.7663 - val_loss: 0.8744 - val_accuracy: 0.7839\n",
            "Epoch 90/100\n",
            "127/127 [==============================] - 58s 459ms/step - loss: 0.8385 - accuracy: 0.7677 - val_loss: 0.8703 - val_accuracy: 0.7837\n",
            "Epoch 91/100\n",
            "127/127 [==============================] - 58s 460ms/step - loss: 0.8329 - accuracy: 0.7669 - val_loss: 0.8770 - val_accuracy: 0.7818\n",
            "Epoch 92/100\n",
            "127/127 [==============================] - 59s 466ms/step - loss: 0.8318 - accuracy: 0.7688 - val_loss: 0.8750 - val_accuracy: 0.7840\n",
            "Epoch 93/100\n",
            "127/127 [==============================] - 59s 466ms/step - loss: 0.8297 - accuracy: 0.7701 - val_loss: 0.8641 - val_accuracy: 0.7849\n",
            "Epoch 94/100\n",
            "127/127 [==============================] - 59s 464ms/step - loss: 0.8294 - accuracy: 0.7693 - val_loss: 0.8711 - val_accuracy: 0.7844\n",
            "Epoch 95/100\n",
            "127/127 [==============================] - 59s 461ms/step - loss: 0.8284 - accuracy: 0.7696 - val_loss: 0.8720 - val_accuracy: 0.7849\n",
            "Epoch 96/100\n",
            "127/127 [==============================] - 59s 468ms/step - loss: 0.8280 - accuracy: 0.7693 - val_loss: 0.8674 - val_accuracy: 0.7850\n",
            "Epoch 97/100\n",
            "127/127 [==============================] - 59s 463ms/step - loss: 0.8227 - accuracy: 0.7691 - val_loss: 0.8708 - val_accuracy: 0.7847\n",
            "Epoch 98/100\n",
            "127/127 [==============================] - 59s 462ms/step - loss: 0.8193 - accuracy: 0.7707 - val_loss: 0.8656 - val_accuracy: 0.7858\n",
            "Epoch 99/100\n",
            "127/127 [==============================] - 58s 460ms/step - loss: 0.8179 - accuracy: 0.7723 - val_loss: 0.8667 - val_accuracy: 0.7862\n",
            "Epoch 100/100\n",
            "127/127 [==============================] - 59s 461ms/step - loss: 0.8171 - accuracy: 0.7728 - val_loss: 0.8723 - val_accuracy: 0.7850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGllmK-j5783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "8387021b-b9cd-4577-abfb-156820ee5de6"
      },
      "source": [
        "s, (at, al) = plt.subplots(2,1)\n",
        "at.plot(history.history['accuracy'], c= 'b')\n",
        "at.plot(history.history['val_accuracy'], c='r')\n",
        "at.set_title('model accuracy')\n",
        "at.set_ylabel('accuracy')\n",
        "at.set_xlabel('epoch')\n",
        "at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\n",
        "\n",
        "al.plot(history.history['loss'], c='m')\n",
        "al.plot(history.history['val_loss'], c='c')\n",
        "al.set_title('model loss')\n",
        "al.set_ylabel('loss')\n",
        "al.set_xlabel('epoch')\n",
        "al.legend(['train', 'val'], loc = 'upper left')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7652a7d750>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unvk7dla6O9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4531647f-6c8a-4d9e-80c5-3381c1dd9c58"
      },
      "source": [
        "def decode_sentiment(score):\n",
        "    return np.argmax(score) \n",
        "\n",
        "\n",
        "y_pred_1d = model.predict(x_test, verbose=1, batch_size=10000)\n",
        "y_pred_1d = [decode_sentiment(score) for score in scores]\n",
        "y_pred_1d"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 140ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[196,\n",
              " 228,\n",
              " 198,\n",
              " 169,\n",
              " 214,\n",
              " 142,\n",
              " 40,\n",
              " 58,\n",
              " 124,\n",
              " 101,\n",
              " 147,\n",
              " 132,\n",
              " 95,\n",
              " 185,\n",
              " 27,\n",
              " 200,\n",
              " 10,\n",
              " 67,\n",
              " 95,\n",
              " 15,\n",
              " 127,\n",
              " 182,\n",
              " 185,\n",
              " 140,\n",
              " 34,\n",
              " 147,\n",
              " 124,\n",
              " 43,\n",
              " 27,\n",
              " 138,\n",
              " 134,\n",
              " 145,\n",
              " 130,\n",
              " 92,\n",
              " 75,\n",
              " 233,\n",
              " 94,\n",
              " 110,\n",
              " 179,\n",
              " 119,\n",
              " 264,\n",
              " 10,\n",
              " 51,\n",
              " 134,\n",
              " 140,\n",
              " 140,\n",
              " 34,\n",
              " 46,\n",
              " 267,\n",
              " 228,\n",
              " 64,\n",
              " 46,\n",
              " 194,\n",
              " 75,\n",
              " 55,\n",
              " 229,\n",
              " 34,\n",
              " 239,\n",
              " 170,\n",
              " 240,\n",
              " 32,\n",
              " 34,\n",
              " 72,\n",
              " 186,\n",
              " 241,\n",
              " 46,\n",
              " 34,\n",
              " 241,\n",
              " 48,\n",
              " 110,\n",
              " 93,\n",
              " 40,\n",
              " 39,\n",
              " 178,\n",
              " 110,\n",
              " 70,\n",
              " 223,\n",
              " 129,\n",
              " 226,\n",
              " 146,\n",
              " 65,\n",
              " 65,\n",
              " 46,\n",
              " 96,\n",
              " 226,\n",
              " 199,\n",
              " 38,\n",
              " 43,\n",
              " 70,\n",
              " 130,\n",
              " 120,\n",
              " 186,\n",
              " 178,\n",
              " 169,\n",
              " 241,\n",
              " 46,\n",
              " 221,\n",
              " 170,\n",
              " 95,\n",
              " 46,\n",
              " 64,\n",
              " 216,\n",
              " 234,\n",
              " 97,\n",
              " 122,\n",
              " 226,\n",
              " 264,\n",
              " 120,\n",
              " 130,\n",
              " 199,\n",
              " 127,\n",
              " 224,\n",
              " 134,\n",
              " 34,\n",
              " 140,\n",
              " 142,\n",
              " 51,\n",
              " 186,\n",
              " 170,\n",
              " 140,\n",
              " 130,\n",
              " 167,\n",
              " 39,\n",
              " 39,\n",
              " 235,\n",
              " 223,\n",
              " 39,\n",
              " 15,\n",
              " 185,\n",
              " 170,\n",
              " 44,\n",
              " 185,\n",
              " 21,\n",
              " 218,\n",
              " 228,\n",
              " 233,\n",
              " 187,\n",
              " 160,\n",
              " 142,\n",
              " 122,\n",
              " 267,\n",
              " 51,\n",
              " 99,\n",
              " 146,\n",
              " 207,\n",
              " 105,\n",
              " 237,\n",
              " 122,\n",
              " 23,\n",
              " 61,\n",
              " 95,\n",
              " 83,\n",
              " 222,\n",
              " 78,\n",
              " 73,\n",
              " 221,\n",
              " 46,\n",
              " 170,\n",
              " 64,\n",
              " 243,\n",
              " 92,\n",
              " 96,\n",
              " 38,\n",
              " 49,\n",
              " 222,\n",
              " 15,\n",
              " 51,\n",
              " 105,\n",
              " 153,\n",
              " 153,\n",
              " 221,\n",
              " 12,\n",
              " 70,\n",
              " 130,\n",
              " 236,\n",
              " 140,\n",
              " 123,\n",
              " 127,\n",
              " 156,\n",
              " 170,\n",
              " 23,\n",
              " 130,\n",
              " 226,\n",
              " 223,\n",
              " 61,\n",
              " 50,\n",
              " 47,\n",
              " 40,\n",
              " 69,\n",
              " 126,\n",
              " 15,\n",
              " 226,\n",
              " 233,\n",
              " 47,\n",
              " 241,\n",
              " 228,\n",
              " 100,\n",
              " 146,\n",
              " 136,\n",
              " 40,\n",
              " 95,\n",
              " 38,\n",
              " 237,\n",
              " 224,\n",
              " 145,\n",
              " 144,\n",
              " 5,\n",
              " 32,\n",
              " 25,\n",
              " 20,\n",
              " 0,\n",
              " 127,\n",
              " 169,\n",
              " 34,\n",
              " 214,\n",
              " 111,\n",
              " 70,\n",
              " 97,\n",
              " 224,\n",
              " 99,\n",
              " 224,\n",
              " 233,\n",
              " 36,\n",
              " 124,\n",
              " 214,\n",
              " 243,\n",
              " 95,\n",
              " 224,\n",
              " 90,\n",
              " 51,\n",
              " 258,\n",
              " 14,\n",
              " 224,\n",
              " 127,\n",
              " 268,\n",
              " 68,\n",
              " 64,\n",
              " 34,\n",
              " 70,\n",
              " 65,\n",
              " 185,\n",
              " 228,\n",
              " 213,\n",
              " 185,\n",
              " 226,\n",
              " 210,\n",
              " 65,\n",
              " 187,\n",
              " 70,\n",
              " 129,\n",
              " 95,\n",
              " 137,\n",
              " 187,\n",
              " 136,\n",
              " 39,\n",
              " 160,\n",
              " 43,\n",
              " 220,\n",
              " 208,\n",
              " 187,\n",
              " 243,\n",
              " 12,\n",
              " 50,\n",
              " 10,\n",
              " 196,\n",
              " 49,\n",
              " 146,\n",
              " 113,\n",
              " 241,\n",
              " 43,\n",
              " 46,\n",
              " 90,\n",
              " 127,\n",
              " 94,\n",
              " 21,\n",
              " 96,\n",
              " 10,\n",
              " 50,\n",
              " 186,\n",
              " 243,\n",
              " 0,\n",
              " 213,\n",
              " 165,\n",
              " 221,\n",
              " 182,\n",
              " 264,\n",
              " 144,\n",
              " 235,\n",
              " 229,\n",
              " 101,\n",
              " 228,\n",
              " 182,\n",
              " 81,\n",
              " 221,\n",
              " 123,\n",
              " 267,\n",
              " 273,\n",
              " 187,\n",
              " 110,\n",
              " 205,\n",
              " 226,\n",
              " 95,\n",
              " 200,\n",
              " 223,\n",
              " 134,\n",
              " 46,\n",
              " 78,\n",
              " 7,\n",
              " 65,\n",
              " 61,\n",
              " 99,\n",
              " 79,\n",
              " 185,\n",
              " 23,\n",
              " 96,\n",
              " 46,\n",
              " 273,\n",
              " 17,\n",
              " 74,\n",
              " 97,\n",
              " 137,\n",
              " 0,\n",
              " 65,\n",
              " 34,\n",
              " 61,\n",
              " 64,\n",
              " 221,\n",
              " 187,\n",
              " 186,\n",
              " 10,\n",
              " 95,\n",
              " 99,\n",
              " 110,\n",
              " 127,\n",
              " 39,\n",
              " 129,\n",
              " 34,\n",
              " 99,\n",
              " 75,\n",
              " 122,\n",
              " 8,\n",
              " 162,\n",
              " 0,\n",
              " 23,\n",
              " 151,\n",
              " 149,\n",
              " 233,\n",
              " 40,\n",
              " 80,\n",
              " 214,\n",
              " 34,\n",
              " 176,\n",
              " 51,\n",
              " 10,\n",
              " 57,\n",
              " 224,\n",
              " 216,\n",
              " 111,\n",
              " 232,\n",
              " 187,\n",
              " 83,\n",
              " 226,\n",
              " 130,\n",
              " 123,\n",
              " 108,\n",
              " 46,\n",
              " 179,\n",
              " 170,\n",
              " 183,\n",
              " 140,\n",
              " 273,\n",
              " 127,\n",
              " 116,\n",
              " 105,\n",
              " 134,\n",
              " 152,\n",
              " 131,\n",
              " 81,\n",
              " 95,\n",
              " 226,\n",
              " 267,\n",
              " 54,\n",
              " 46,\n",
              " 46,\n",
              " 238,\n",
              " 88,\n",
              " 243,\n",
              " 99,\n",
              " 220,\n",
              " 70,\n",
              " 123,\n",
              " 122,\n",
              " 108,\n",
              " 54,\n",
              " 155,\n",
              " 130,\n",
              " 228,\n",
              " 144,\n",
              " 75,\n",
              " 130,\n",
              " 124,\n",
              " 99,\n",
              " 129,\n",
              " 64,\n",
              " 68,\n",
              " 61,\n",
              " 220,\n",
              " 224,\n",
              " 193,\n",
              " 199,\n",
              " 70,\n",
              " 244,\n",
              " 65,\n",
              " 207,\n",
              " 241,\n",
              " 68,\n",
              " 118,\n",
              " 130,\n",
              " 180,\n",
              " 203,\n",
              " 24,\n",
              " 64,\n",
              " 156,\n",
              " 40,\n",
              " 140,\n",
              " 193,\n",
              " 130,\n",
              " 144,\n",
              " 130,\n",
              " 113,\n",
              " 142,\n",
              " 232,\n",
              " 210,\n",
              " 189,\n",
              " 120,\n",
              " 233,\n",
              " 122,\n",
              " 110,\n",
              " 64,\n",
              " 144,\n",
              " 223,\n",
              " 69,\n",
              " 159,\n",
              " 119,\n",
              " 251,\n",
              " 226,\n",
              " 81,\n",
              " 245,\n",
              " 34,\n",
              " 95,\n",
              " 129,\n",
              " 34,\n",
              " 19,\n",
              " 32,\n",
              " 210,\n",
              " 143,\n",
              " 181,\n",
              " 214,\n",
              " 70,\n",
              " 186,\n",
              " 130,\n",
              " 40,\n",
              " 134,\n",
              " 241,\n",
              " 219,\n",
              " 25,\n",
              " 99,\n",
              " 6,\n",
              " 81,\n",
              " 221,\n",
              " 78,\n",
              " 136,\n",
              " 89,\n",
              " 95,\n",
              " 121,\n",
              " 272,\n",
              " 224,\n",
              " 210,\n",
              " 223,\n",
              " 156,\n",
              " 205,\n",
              " 118,\n",
              " 181,\n",
              " 96,\n",
              " 140,\n",
              " 69,\n",
              " 224,\n",
              " 267,\n",
              " 183,\n",
              " 69,\n",
              " 270,\n",
              " 243,\n",
              " 134,\n",
              " 228,\n",
              " 76,\n",
              " 68,\n",
              " 214,\n",
              " 185,\n",
              " 10,\n",
              " 228,\n",
              " 15,\n",
              " 28,\n",
              " 96,\n",
              " 236,\n",
              " 95,\n",
              " 42,\n",
              " 95,\n",
              " 34,\n",
              " 15,\n",
              " 241,\n",
              " 156,\n",
              " 208,\n",
              " 182,\n",
              " 130,\n",
              " 226,\n",
              " 185,\n",
              " 27,\n",
              " 130,\n",
              " 46,\n",
              " 43,\n",
              " 235,\n",
              " 51,\n",
              " 32,\n",
              " 70,\n",
              " 244,\n",
              " 72,\n",
              " 120,\n",
              " 145,\n",
              " 140,\n",
              " 160,\n",
              " 230,\n",
              " 70,\n",
              " 70,\n",
              " 181,\n",
              " 40,\n",
              " 187,\n",
              " 220,\n",
              " 264,\n",
              " 15,\n",
              " 70,\n",
              " 74,\n",
              " 51,\n",
              " 76,\n",
              " 187,\n",
              " 130,\n",
              " 214,\n",
              " 95,\n",
              " 129,\n",
              " 90,\n",
              " 130,\n",
              " 232,\n",
              " 170,\n",
              " 55,\n",
              " 32,\n",
              " 140,\n",
              " 89,\n",
              " 69,\n",
              " 95,\n",
              " 64,\n",
              " 232,\n",
              " 271,\n",
              " 168,\n",
              " 136,\n",
              " 96,\n",
              " 130,\n",
              " 123,\n",
              " 73,\n",
              " 237,\n",
              " 56,\n",
              " 189,\n",
              " 226,\n",
              " 130,\n",
              " 105,\n",
              " 224,\n",
              " 244,\n",
              " 151,\n",
              " 123,\n",
              " 224,\n",
              " 134,\n",
              " 140,\n",
              " 170,\n",
              " 181,\n",
              " 170,\n",
              " 110,\n",
              " 70,\n",
              " 222,\n",
              " 264,\n",
              " 94,\n",
              " 251,\n",
              " 101,\n",
              " 197,\n",
              " 169,\n",
              " 127,\n",
              " 159,\n",
              " 243,\n",
              " 92,\n",
              " 90,\n",
              " 136,\n",
              " 144,\n",
              " 19,\n",
              " 156,\n",
              " 50,\n",
              " 32,\n",
              " 92,\n",
              " 69,\n",
              " 70,\n",
              " 162,\n",
              " 95,\n",
              " 149,\n",
              " 210,\n",
              " 140,\n",
              " 27,\n",
              " 183,\n",
              " 224,\n",
              " 130,\n",
              " 224,\n",
              " 79,\n",
              " 130,\n",
              " 222,\n",
              " 108,\n",
              " 34,\n",
              " 21,\n",
              " 15,\n",
              " 204,\n",
              " 34,\n",
              " 130,\n",
              " 144,\n",
              " 99,\n",
              " 187,\n",
              " 268,\n",
              " 90,\n",
              " 99,\n",
              " 36,\n",
              " 130,\n",
              " 61,\n",
              " 34,\n",
              " 180,\n",
              " 182,\n",
              " 153,\n",
              " 69,\n",
              " 130,\n",
              " 15,\n",
              " 122,\n",
              " 47,\n",
              " 129,\n",
              " 20,\n",
              " 34,\n",
              " 137,\n",
              " 54,\n",
              " 245,\n",
              " 178,\n",
              " 64,\n",
              " 41,\n",
              " 51,\n",
              " 46,\n",
              " 113,\n",
              " 223,\n",
              " 41,\n",
              " 95,\n",
              " 226,\n",
              " 34,\n",
              " 153,\n",
              " 232,\n",
              " 221,\n",
              " 78,\n",
              " 178,\n",
              " 140,\n",
              " 165,\n",
              " 34,\n",
              " 226,\n",
              " 223,\n",
              " 20,\n",
              " 182,\n",
              " 136,\n",
              " 277,\n",
              " 153,\n",
              " 129,\n",
              " 94,\n",
              " 190,\n",
              " 183,\n",
              " 137,\n",
              " 75,\n",
              " 187,\n",
              " 88,\n",
              " 70,\n",
              " 139,\n",
              " 222,\n",
              " 76,\n",
              " 73,\n",
              " 265,\n",
              " 187,\n",
              " 181,\n",
              " 197,\n",
              " 32,\n",
              " 170,\n",
              " 153,\n",
              " 46,\n",
              " 74,\n",
              " 118,\n",
              " 145,\n",
              " 97,\n",
              " 50,\n",
              " 96,\n",
              " 186,\n",
              " 241,\n",
              " 130,\n",
              " 23,\n",
              " 183,\n",
              " 110,\n",
              " 113,\n",
              " 176,\n",
              " 244,\n",
              " 277,\n",
              " 45,\n",
              " 129,\n",
              " 130,\n",
              " 113,\n",
              " 224,\n",
              " 147,\n",
              " 110,\n",
              " 90,\n",
              " 106,\n",
              " 114,\n",
              " 210,\n",
              " 61,\n",
              " 74,\n",
              " 108,\n",
              " 99,\n",
              " 34,\n",
              " 94,\n",
              " 78,\n",
              " 224,\n",
              " 110,\n",
              " 21,\n",
              " 205,\n",
              " 179,\n",
              " 236,\n",
              " 170,\n",
              " 232,\n",
              " 75,\n",
              " 130,\n",
              " 156,\n",
              " 180,\n",
              " 78,\n",
              " 273,\n",
              " 72,\n",
              " 233,\n",
              " 229,\n",
              " 124,\n",
              " 168,\n",
              " 94,\n",
              " 181,\n",
              " 193,\n",
              " 110,\n",
              " 210,\n",
              " 127,\n",
              " 224,\n",
              " 58,\n",
              " 162,\n",
              " 46,\n",
              " 232,\n",
              " 70,\n",
              " 223,\n",
              " 221,\n",
              " 99,\n",
              " 70,\n",
              " 34,\n",
              " 70,\n",
              " 214,\n",
              " 95,\n",
              " 95,\n",
              " 36,\n",
              " 46,\n",
              " 130,\n",
              " 210,\n",
              " 96,\n",
              " 51,\n",
              " 104,\n",
              " 122,\n",
              " 34,\n",
              " 268,\n",
              " 21,\n",
              " 222,\n",
              " 121,\n",
              " 41,\n",
              " 70,\n",
              " 130,\n",
              " 39,\n",
              " 266,\n",
              " 23,\n",
              " 123,\n",
              " 235,\n",
              " 140,\n",
              " 238,\n",
              " 34,\n",
              " 15,\n",
              " 96,\n",
              " 134,\n",
              " 235,\n",
              " 133,\n",
              " 40,\n",
              " 0,\n",
              " 110,\n",
              " 216,\n",
              " 49,\n",
              " 94,\n",
              " 75,\n",
              " 130,\n",
              " 142,\n",
              " 78,\n",
              " 52,\n",
              " 127,\n",
              " 139,\n",
              " 6,\n",
              " 187,\n",
              " 95,\n",
              " 145,\n",
              " 195,\n",
              " 46,\n",
              " 187,\n",
              " 267,\n",
              " 34,\n",
              " 34,\n",
              " 264,\n",
              " 69,\n",
              " 210,\n",
              " 228,\n",
              " 187,\n",
              " 122,\n",
              " 134,\n",
              " 232,\n",
              " 133,\n",
              " 153,\n",
              " 185,\n",
              " 90,\n",
              " 228,\n",
              " 36,\n",
              " 130,\n",
              " 70,\n",
              " 87,\n",
              " 64,\n",
              " 241,\n",
              " 217,\n",
              " 160,\n",
              " 84,\n",
              " 122,\n",
              " 130,\n",
              " 224,\n",
              " 23,\n",
              " 99,\n",
              " 61,\n",
              " 129,\n",
              " 11,\n",
              " 64,\n",
              " 43,\n",
              " 103,\n",
              " 200,\n",
              " 130,\n",
              " 39,\n",
              " 51,\n",
              " 51,\n",
              " 46,\n",
              " 72,\n",
              " 245,\n",
              " 194,\n",
              " 10,\n",
              " 213,\n",
              " 40,\n",
              " 119,\n",
              " 229,\n",
              " 40,\n",
              " 110,\n",
              " 119,\n",
              " 64,\n",
              " 65,\n",
              " 62,\n",
              " 186,\n",
              " 69,\n",
              " 71,\n",
              " 47,\n",
              " 99,\n",
              " 243,\n",
              " 222,\n",
              " 229,\n",
              " 241,\n",
              " 176,\n",
              " 12,\n",
              " 34,\n",
              " 243,\n",
              " 160,\n",
              " 34,\n",
              " 181,\n",
              " 214,\n",
              " 130,\n",
              " 153,\n",
              " 270,\n",
              " 99,\n",
              " 140,\n",
              " 64,\n",
              " 122,\n",
              " 266,\n",
              " 70,\n",
              " 123,\n",
              " 226,\n",
              " 232,\n",
              " 94,\n",
              " 224,\n",
              " 221,\n",
              " 92,\n",
              " 71,\n",
              " 95,\n",
              " 200,\n",
              " 134,\n",
              " 130,\n",
              " 120,\n",
              " 241,\n",
              " 110,\n",
              " 228,\n",
              " 130,\n",
              " 109,\n",
              " 44,\n",
              " 264,\n",
              " 34,\n",
              " 199,\n",
              " 87,\n",
              " 63,\n",
              " 94,\n",
              " 178,\n",
              " 181,\n",
              " 222,\n",
              " 51,\n",
              " 123,\n",
              " 96,\n",
              " 185,\n",
              " 50,\n",
              " 222,\n",
              " 153,\n",
              " 27,\n",
              " 10,\n",
              " 41,\n",
              " 210,\n",
              " 187,\n",
              " 241,\n",
              " 140,\n",
              " 224,\n",
              " 69,\n",
              " 111,\n",
              " 126,\n",
              " 10,\n",
              " 46,\n",
              " 58,\n",
              " 226,\n",
              " 200,\n",
              " 130,\n",
              " 224,\n",
              " 127,\n",
              " 226,\n",
              " 122,\n",
              " 147,\n",
              " 273,\n",
              " 123,\n",
              " 120,\n",
              " 122,\n",
              " 182,\n",
              " 122,\n",
              " 264,\n",
              " 79,\n",
              " 106,\n",
              " 39,\n",
              " 156,\n",
              " 128,\n",
              " 34,\n",
              " 74,\n",
              " 189,\n",
              " 76,\n",
              " 61,\n",
              " 178,\n",
              " 12,\n",
              " 39,\n",
              " 220,\n",
              " 58,\n",
              " 128,\n",
              " 185,\n",
              " 12,\n",
              " 153,\n",
              " 144,\n",
              " 92,\n",
              " 92,\n",
              " 70,\n",
              " 206,\n",
              " 120,\n",
              " 110,\n",
              " 189,\n",
              " 39,\n",
              " 140,\n",
              " 70,\n",
              " 244,\n",
              " 246,\n",
              " 65,\n",
              " 214,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B48PqGFw6SDV"
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, fontsize=13)\n",
        "    plt.yticks(tick_marks, classes, fontsize=13)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label', fontsize=17)\n",
        "    plt.xlabel('Predicted label', fontsize=17)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXIFb9XK6VCx"
      },
      "source": [
        "\"\"\"cnf_matrix = confusion_matrix(test_data.label.to_list(), y_pred_1d)\n",
        "plt.figure(figsize=(6,6))\n",
        "plot_confusion_matrix(cnf_matrix, classes=test_data.label.unique(), title=\"Confusion matrix\")\n",
        "plt.show()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WO1pq-J6XRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5f7fb2-c6e5-4e9d-cf8e-4f887e4aa6fc"
      },
      "source": [
        "print(classification_report(list(test_data.label), y_pred_1d))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "           2       0.00      0.00      0.00       0.0\n",
            "           3       0.00      0.00      0.00       0.0\n",
            "           4       0.00      0.00      0.00       0.0\n",
            "           5       0.00      0.00      0.00       0.0\n",
            "           6       0.00      0.00      0.00       0.0\n",
            "           7       0.00      0.00      0.00       0.0\n",
            "           8       0.00      0.00      0.00       0.0\n",
            "           9       0.00      0.00      0.00       0.0\n",
            "          10       0.00      0.00      0.00       0.0\n",
            "          11       0.00      0.00      0.00       0.0\n",
            "          12       0.00      0.00      0.00       0.0\n",
            "          13       0.00      0.00      0.00       0.0\n",
            "          14       0.00      0.00      0.00       0.0\n",
            "          15       0.00      0.00      0.00       0.0\n",
            "          16       0.00      0.00      0.00       0.0\n",
            "          17       0.00      0.00      0.00       0.0\n",
            "          18       0.00      0.00      0.00       0.0\n",
            "          19       0.00      0.00      0.00       0.0\n",
            "          20       0.00      0.00      0.00       0.0\n",
            "          21       0.00      0.00      0.00       0.0\n",
            "          22       0.00      0.00      0.00       0.0\n",
            "          23       0.00      0.00      0.00       0.0\n",
            "          24       0.00      0.00      0.00       0.0\n",
            "          25       0.00      0.00      0.00       0.0\n",
            "          26       0.00      0.00      0.00       0.0\n",
            "          27       0.00      0.00      0.00       0.0\n",
            "          28       0.00      0.00      0.00       0.0\n",
            "          29       0.00      0.00      0.00       0.0\n",
            "          30       0.00      0.00      0.00       0.0\n",
            "          31       0.00      0.00      0.00       0.0\n",
            "          32       0.00      0.00      0.00       0.0\n",
            "          33       0.00      0.00      0.00       0.0\n",
            "          34       0.00      0.00      0.00       0.0\n",
            "          35       0.00      0.00      0.00       0.0\n",
            "          36       0.00      0.00      0.00       0.0\n",
            "          37       0.00      0.00      0.00       0.0\n",
            "          38       0.00      0.00      0.00       0.0\n",
            "          39       0.00      0.00      0.00       0.0\n",
            "          40       0.00      0.00      0.00       0.0\n",
            "          41       0.00      0.00      0.00       0.0\n",
            "          42       0.00      0.00      0.00       0.0\n",
            "          43       0.00      0.00      0.00       0.0\n",
            "          44       0.00      0.00      0.00       0.0\n",
            "          45       0.00      0.00      0.00       0.0\n",
            "          46       0.00      0.00      0.00       0.0\n",
            "          47       0.00      0.00      0.00       0.0\n",
            "          48       0.00      0.00      0.00       0.0\n",
            "          49       0.00      0.00      0.00       0.0\n",
            "          50       0.00      0.00      0.00       0.0\n",
            "          51       0.00      0.00      0.00       0.0\n",
            "          52       0.00      0.00      0.00       0.0\n",
            "          53       0.00      0.00      0.00       0.0\n",
            "          54       0.00      0.00      0.00       0.0\n",
            "          55       0.00      0.00      0.00       0.0\n",
            "          56       0.00      0.00      0.00       0.0\n",
            "          57       0.00      0.00      0.00       0.0\n",
            "          58       0.00      0.00      0.00       0.0\n",
            "          59       0.00      0.00      0.00       0.0\n",
            "          60       0.00      0.00      0.00       0.0\n",
            "          61       0.00      0.00      0.00       0.0\n",
            "          62       0.00      0.00      0.00       0.0\n",
            "          63       0.00      0.00      0.00       0.0\n",
            "          64       0.00      0.00      0.00       0.0\n",
            "          65       0.00      0.00      0.00       0.0\n",
            "          66       0.00      0.00      0.00       0.0\n",
            "          67       0.00      0.00      0.00       0.0\n",
            "          68       0.00      0.00      0.00       0.0\n",
            "          69       0.00      0.00      0.00       0.0\n",
            "          70       0.00      0.00      0.00       0.0\n",
            "          71       0.00      0.00      0.00       0.0\n",
            "          72       0.00      0.00      0.00       0.0\n",
            "          73       0.00      0.00      0.00       0.0\n",
            "          74       0.00      0.00      0.00       0.0\n",
            "          75       0.00      0.00      0.00       0.0\n",
            "          76       0.00      0.00      0.00       0.0\n",
            "          77       0.00      0.00      0.00       0.0\n",
            "          78       0.00      0.00      0.00       0.0\n",
            "          79       0.00      0.00      0.00       0.0\n",
            "          80       0.00      0.00      0.00       0.0\n",
            "          81       0.00      0.00      0.00       0.0\n",
            "          82       0.00      0.00      0.00       0.0\n",
            "          83       0.00      0.00      0.00       0.0\n",
            "          84       0.00      0.00      0.00       0.0\n",
            "          85       0.00      0.00      0.00       0.0\n",
            "          86       0.00      0.00      0.00       0.0\n",
            "          87       0.00      0.00      0.00       0.0\n",
            "          88       0.00      0.00      0.00       0.0\n",
            "          89       0.00      0.00      0.00       0.0\n",
            "          90       0.00      0.00      0.00       0.0\n",
            "          91       0.00      0.00      0.00       0.0\n",
            "          92       0.00      0.00      0.00       0.0\n",
            "          93       0.00      0.00      0.00       0.0\n",
            "          94       0.00      0.00      0.00       0.0\n",
            "          95       0.00      0.00      0.00       0.0\n",
            "          96       0.00      0.00      0.00       0.0\n",
            "          97       0.00      0.00      0.00       0.0\n",
            "          98       0.00      0.00      0.00       0.0\n",
            "          99       0.00      0.00      0.00       0.0\n",
            "         100       0.00      0.00      0.00       0.0\n",
            "         101       0.00      0.00      0.00       0.0\n",
            "         102       0.00      0.00      0.00       0.0\n",
            "         103       0.00      0.00      0.00       0.0\n",
            "         104       0.00      0.00      0.00       0.0\n",
            "         105       0.00      0.00      0.00       0.0\n",
            "         106       0.00      0.00      0.00       0.0\n",
            "         107       0.00      0.00      0.00       0.0\n",
            "         108       0.00      0.00      0.00       0.0\n",
            "         109       0.00      0.00      0.00       0.0\n",
            "         110       0.00      0.00      0.00       0.0\n",
            "         111       0.00      0.00      0.00       0.0\n",
            "         112       0.00      0.00      0.00       0.0\n",
            "         113       0.00      0.00      0.00       0.0\n",
            "         114       0.00      0.00      0.00       0.0\n",
            "         115       0.00      0.00      0.00       0.0\n",
            "         116       0.00      0.00      0.00       0.0\n",
            "         117       0.00      0.00      0.00       0.0\n",
            "         118       0.00      0.00      0.00       0.0\n",
            "         119       0.00      0.00      0.00       0.0\n",
            "         120       0.00      0.00      0.00       0.0\n",
            "         121       0.00      0.00      0.00       0.0\n",
            "         122       0.00      0.00      0.00       0.0\n",
            "         123       0.00      0.00      0.00       0.0\n",
            "         124       0.00      0.00      0.00       0.0\n",
            "         125       0.00      0.00      0.00       0.0\n",
            "         126       0.00      0.00      0.00       0.0\n",
            "         127       0.00      0.00      0.00       0.0\n",
            "         128       0.00      0.00      0.00       0.0\n",
            "         129       0.00      0.00      0.00       0.0\n",
            "         130       0.00      0.00      0.00       0.0\n",
            "         131       0.00      0.00      0.00       0.0\n",
            "         132       0.00      0.00      0.00       0.0\n",
            "         133       0.00      0.00      0.00       0.0\n",
            "         134       0.00      0.00      0.00       0.0\n",
            "         135       0.00      0.00      0.00       0.0\n",
            "         136       0.00      0.00      0.00       0.0\n",
            "         137       0.00      0.00      0.00       0.0\n",
            "         138       0.00      0.00      0.00       0.0\n",
            "         139       0.00      0.00      0.00       0.0\n",
            "         140       0.00      0.00      0.00       0.0\n",
            "         141       0.00      0.00      0.00       0.0\n",
            "         142       0.00      0.00      0.00       0.0\n",
            "         143       0.00      0.00      0.00       0.0\n",
            "         144       0.00      0.00      0.00       0.0\n",
            "         145       0.00      0.00      0.00       0.0\n",
            "         146       0.00      0.00      0.00       0.0\n",
            "         147       0.00      0.00      0.00       0.0\n",
            "         148       0.00      0.00      0.00       0.0\n",
            "         149       0.00      0.00      0.00       0.0\n",
            "         150       0.00      0.00      0.00       0.0\n",
            "         151       0.00      0.00      0.00       0.0\n",
            "         152       0.00      0.00      0.00       0.0\n",
            "         153       0.00      0.00      0.00       0.0\n",
            "         154       0.00      0.00      0.00       0.0\n",
            "         155       0.00      0.00      0.00       0.0\n",
            "         156       0.00      0.00      0.00       0.0\n",
            "         157       0.00      0.00      0.00       0.0\n",
            "         158       0.00      0.00      0.00       0.0\n",
            "         159       0.00      0.00      0.00       0.0\n",
            "         160       0.00      0.00      0.00       0.0\n",
            "         161       0.00      0.00      0.00       0.0\n",
            "         162       0.00      0.00      0.00       0.0\n",
            "         163       0.00      0.00      0.00       0.0\n",
            "         164       0.00      0.00      0.00       0.0\n",
            "         165       0.00      0.00      0.00       0.0\n",
            "         166       0.00      0.00      0.00       0.0\n",
            "         167       0.00      0.00      0.00       0.0\n",
            "         168       0.00      0.00      0.00       0.0\n",
            "         169       0.00      0.00      0.00       0.0\n",
            "         170       0.00      0.00      0.00       0.0\n",
            "         171       0.00      0.00      0.00       0.0\n",
            "         172       0.00      0.00      0.00       0.0\n",
            "         173       0.00      0.00      0.00       0.0\n",
            "         174       0.00      0.00      0.00       0.0\n",
            "         175       0.00      0.00      0.00       0.0\n",
            "         176       0.00      0.00      0.00       0.0\n",
            "         177       0.00      0.00      0.00       0.0\n",
            "         178       0.00      0.00      0.00       0.0\n",
            "         179       0.00      0.00      0.00       0.0\n",
            "         180       0.00      0.00      0.00       0.0\n",
            "         181       0.00      0.00      0.00       0.0\n",
            "         182       0.00      0.00      0.00       0.0\n",
            "         183       0.00      0.00      0.00       0.0\n",
            "         184       0.00      0.00      0.00       0.0\n",
            "         185       0.00      0.00      0.00       0.0\n",
            "         186       0.00      0.00      0.00       0.0\n",
            "         187       0.00      0.00      0.00       0.0\n",
            "         188       0.00      0.00      0.00       0.0\n",
            "         189       0.00      0.00      0.00       0.0\n",
            "         190       0.00      0.00      0.00       0.0\n",
            "         191       0.00      0.00      0.00       0.0\n",
            "         193       0.00      0.00      0.00       0.0\n",
            "         194       0.00      0.00      0.00       0.0\n",
            "         195       0.00      0.00      0.00       0.0\n",
            "         196       0.00      0.00      0.00       0.0\n",
            "         197       0.00      0.00      0.00       0.0\n",
            "         198       0.00      0.00      0.00       0.0\n",
            "         199       0.00      0.00      0.00       0.0\n",
            "         200       0.00      0.00      0.00       0.0\n",
            "         201       0.00      0.00      0.00       0.0\n",
            "         202       0.00      0.00      0.00       0.0\n",
            "         203       0.00      0.00      0.00       0.0\n",
            "         204       0.00      0.00      0.00       0.0\n",
            "         205       0.00      0.00      0.00       0.0\n",
            "         206       0.00      0.00      0.00       0.0\n",
            "         207       0.00      0.00      0.00       0.0\n",
            "         208       0.00      0.00      0.00       0.0\n",
            "         209       0.00      0.00      0.00       0.0\n",
            "         210       0.00      0.00      0.00       0.0\n",
            "         211       0.00      0.00      0.00       0.0\n",
            "         212       0.00      0.00      0.00       0.0\n",
            "         213       0.00      0.00      0.00       0.0\n",
            "         214       0.00      0.00      0.00       0.0\n",
            "         215       0.00      0.00      0.00       0.0\n",
            "         216       0.00      0.00      0.00       0.0\n",
            "         217       0.00      0.00      0.00       0.0\n",
            "         218       0.00      0.00      0.00       0.0\n",
            "         219       0.00      0.00      0.00       0.0\n",
            "         220       0.00      0.00      0.00       0.0\n",
            "         221       0.00      0.00      0.00       0.0\n",
            "         222       0.00      0.00      0.00       0.0\n",
            "         223       0.00      0.00      0.00       0.0\n",
            "         224       0.00      0.00      0.00       0.0\n",
            "         225       0.00      0.00      0.00       0.0\n",
            "         226       0.00      0.00      0.00       0.0\n",
            "         227       0.00      0.00      0.00       0.0\n",
            "         228       0.00      0.00      0.00       0.0\n",
            "         229       0.00      0.00      0.00       0.0\n",
            "         230       0.00      0.00      0.00       0.0\n",
            "         232       0.00      0.00      0.00       0.0\n",
            "         233       0.00      0.00      0.00       0.0\n",
            "         234       0.00      0.00      0.00       0.0\n",
            "         235       0.00      0.00      0.00       0.0\n",
            "         236       0.00      0.00      0.00       0.0\n",
            "         237       0.00      0.00      0.00       0.0\n",
            "         238       0.00      0.00      0.00       0.0\n",
            "         239       0.00      0.00      0.00       0.0\n",
            "         240       0.00      0.00      0.00       0.0\n",
            "         241       0.00      0.00      0.00       0.0\n",
            "         242       0.00      0.00      0.00       0.0\n",
            "         243       0.00      0.00      0.00       0.0\n",
            "         244       0.00      0.00      0.00       0.0\n",
            "         245       0.00      0.00      0.00       0.0\n",
            "         246       0.00      0.00      0.00       0.0\n",
            "         247       0.00      0.00      0.00       0.0\n",
            "         248       0.00      0.00      0.00       0.0\n",
            "         249       0.00      0.00      0.00       0.0\n",
            "         250       0.00      0.00      0.00       0.0\n",
            "         251       0.00      0.00      0.00       0.0\n",
            "         253       0.00      0.00      0.00       0.0\n",
            "         254       0.00      0.00      0.00       0.0\n",
            "         255       0.00      0.00      0.00       0.0\n",
            "         256       0.00      0.00      0.00       0.0\n",
            "         257       0.00      0.00      0.00       0.0\n",
            "         258       0.00      0.00      0.00       0.0\n",
            "         260       0.00      0.00      0.00       0.0\n",
            "         263       0.00      0.00      0.00       0.0\n",
            "         264       0.00      0.00      0.00       0.0\n",
            "         265       0.00      0.00      0.00       0.0\n",
            "         266       0.00      0.00      0.00       0.0\n",
            "         267       0.00      0.00      0.00       0.0\n",
            "         268       0.00      0.00      0.00       0.0\n",
            "         269       0.00      0.00      0.00       0.0\n",
            "         270       0.00      0.00      0.00       0.0\n",
            "         271       0.00      0.00      0.00       0.0\n",
            "         272       0.00      0.00      0.00       0.0\n",
            "         273       0.00      0.00      0.00       0.0\n",
            "         274       0.00      0.00      0.00       0.0\n",
            "         277       0.00      0.00      0.00       0.0\n",
            "         278       0.00      0.00      0.00       0.0\n",
            "         279       0.00      0.00      0.00       0.0\n",
            "         293       0.00      0.00      0.00      85.0\n",
            "         294       0.00      0.00      0.00      28.0\n",
            "         295       0.00      0.00      0.00      25.0\n",
            "         312       0.00      0.00      0.00      10.0\n",
            "         313       0.00      0.00      0.00      18.0\n",
            "         314       0.00      0.00      0.00      25.0\n",
            "         329       0.00      0.00      0.00      32.0\n",
            "         331       0.00      0.00      0.00      12.0\n",
            "         332       0.00      0.00      0.00      33.0\n",
            "         333       0.00      0.00      0.00      47.0\n",
            "         334       0.00      0.00      0.00     328.0\n",
            "         335       0.00      0.00      0.00      48.0\n",
            "         336       0.00      0.00      0.00      44.0\n",
            "         337       0.00      0.00      0.00      19.0\n",
            "         338       0.00      0.00      0.00      42.0\n",
            "         339       0.00      0.00      0.00     246.0\n",
            "         342       0.00      0.00      0.00      67.0\n",
            "         343       0.00      0.00      0.00      17.0\n",
            "         344       0.00      0.00      0.00     113.0\n",
            "         346       0.00      0.00      0.00      96.0\n",
            "         348       0.00      0.00      0.00     163.0\n",
            "         349       0.00      0.00      0.00      40.0\n",
            "         350       0.00      0.00      0.00     360.0\n",
            "         351       0.00      0.00      0.00      43.0\n",
            "         353       0.00      0.00      0.00      18.0\n",
            "         355       0.00      0.00      0.00     106.0\n",
            "         356       0.00      0.00      0.00      29.0\n",
            "         357       0.00      0.00      0.00      78.0\n",
            "         362       0.00      0.00      0.00      21.0\n",
            "         363       0.00      0.00      0.00     151.0\n",
            "         366       0.00      0.00      0.00     805.0\n",
            "         367       0.00      0.00      0.00      77.0\n",
            "         368       0.00      0.00      0.00     147.0\n",
            "         370       0.00      0.00      0.00      21.0\n",
            "         372       0.00      0.00      0.00     156.0\n",
            "         373       0.00      0.00      0.00     274.0\n",
            "         375       0.00      0.00      0.00     179.0\n",
            "         377       0.00      0.00      0.00     144.0\n",
            "         378       0.00      0.00      0.00      52.0\n",
            "         379       0.00      0.00      0.00     101.0\n",
            "         380       0.00      0.00      0.00     132.0\n",
            "         381       0.00      0.00      0.00      29.0\n",
            "         382       0.00      0.00      0.00     554.0\n",
            "         383       0.00      0.00      0.00     176.0\n",
            "         384       0.00      0.00      0.00      60.0\n",
            "         385       0.00      0.00      0.00     102.0\n",
            "         386       0.00      0.00      0.00     152.0\n",
            "         387       0.00      0.00      0.00     251.0\n",
            "         388       0.00      0.00      0.00      83.0\n",
            "         389       0.00      0.00      0.00      19.0\n",
            "         390       0.00      0.00      0.00      31.0\n",
            "         391       0.00      0.00      0.00      26.0\n",
            "         392       0.00      0.00      0.00      14.0\n",
            "         393       0.00      0.00      0.00      40.0\n",
            "         394       0.00      0.00      0.00      91.0\n",
            "         395       0.00      0.00      0.00      41.0\n",
            "         399       0.00      0.00      0.00      68.0\n",
            "         400       0.00      0.00      0.00     195.0\n",
            "         401       0.00      0.00      0.00      27.0\n",
            "         402       0.00      0.00      0.00      47.0\n",
            "         403       0.00      0.00      0.00     470.0\n",
            "         404       0.00      0.00      0.00      82.0\n",
            "         405       0.00      0.00      0.00      64.0\n",
            "         406       0.00      0.00      0.00      57.0\n",
            "         407       0.00      0.00      0.00      68.0\n",
            "         408       0.00      0.00      0.00     325.0\n",
            "         409       0.00      0.00      0.00     648.0\n",
            "         410       0.00      0.00      0.00      99.0\n",
            "         411       0.00      0.00      0.00     180.0\n",
            "         412       0.00      0.00      0.00     149.0\n",
            "         413       0.00      0.00      0.00     199.0\n",
            "         415       0.00      0.00      0.00     175.0\n",
            "         416       0.00      0.00      0.00     247.0\n",
            "         417       0.00      0.00      0.00      36.0\n",
            "         418       0.00      0.00      0.00     205.0\n",
            "         419       0.00      0.00      0.00      54.0\n",
            "         420       0.00      0.00      0.00     104.0\n",
            "         421       0.00      0.00      0.00     138.0\n",
            "         422       0.00      0.00      0.00      46.0\n",
            "         423       0.00      0.00      0.00      35.0\n",
            "         424       0.00      0.00      0.00      28.0\n",
            "         425       0.00      0.00      0.00      43.0\n",
            "         426       0.00      0.00      0.00      17.0\n",
            "         427       0.00      0.00      0.00      77.0\n",
            "         429       0.00      0.00      0.00     185.0\n",
            "         430       0.00      0.00      0.00      58.0\n",
            "         431       0.00      0.00      0.00     253.0\n",
            "         432       0.00      0.00      0.00      76.0\n",
            "         433       0.00      0.00      0.00     353.0\n",
            "         434       0.00      0.00      0.00      97.0\n",
            "         435       0.00      0.00      0.00     391.0\n",
            "         438       0.00      0.00      0.00     372.0\n",
            "         439       0.00      0.00      0.00     281.0\n",
            "         440       0.00      0.00      0.00      48.0\n",
            "         442       0.00      0.00      0.00      40.0\n",
            "         443       0.00      0.00      0.00     445.0\n",
            "         444       0.00      0.00      0.00      33.0\n",
            "         445       0.00      0.00      0.00      82.0\n",
            "         446       0.00      0.00      0.00      13.0\n",
            "         447       0.00      0.00      0.00      50.0\n",
            "         448       0.00      0.00      0.00      70.0\n",
            "         449       0.00      0.00      0.00     125.0\n",
            "         450       0.00      0.00      0.00      50.0\n",
            "         453       0.00      0.00      0.00     168.0\n",
            "         454       0.00      0.00      0.00      55.0\n",
            "         455       0.00      0.00      0.00     438.0\n",
            "         459       0.00      0.00      0.00     250.0\n",
            "         460       0.00      0.00      0.00      33.0\n",
            "         461       0.00      0.00      0.00      85.0\n",
            "         462       0.00      0.00      0.00      56.0\n",
            "         466       0.00      0.00      0.00      87.0\n",
            "         467       0.00      0.00      0.00      43.0\n",
            "         468       0.00      0.00      0.00      68.0\n",
            "         469       0.00      0.00      0.00      94.0\n",
            "         470       0.00      0.00      0.00     127.0\n",
            "         471       0.00      0.00      0.00     103.0\n",
            "         473       0.00      0.00      0.00     507.0\n",
            "         474       0.00      0.00      0.00     276.0\n",
            "         477       0.00      0.00      0.00     217.0\n",
            "         481       0.00      0.00      0.00     102.0\n",
            "         483       0.00      0.00      0.00     150.0\n",
            "         484       0.00      0.00      0.00     141.0\n",
            "         485       0.00      0.00      0.00     229.0\n",
            "         490       0.00      0.00      0.00     914.0\n",
            "         495       0.00      0.00      0.00      18.0\n",
            "         497       0.00      0.00      0.00      35.0\n",
            "         499       0.00      0.00      0.00      77.0\n",
            "         500       0.00      0.00      0.00     258.0\n",
            "         502       0.00      0.00      0.00      14.0\n",
            "         503       0.00      0.00      0.00     184.0\n",
            "         507       0.00      0.00      0.00     170.0\n",
            "         508       0.00      0.00      0.00      54.0\n",
            "         509       0.00      0.00      0.00      91.0\n",
            "         510       0.00      0.00      0.00     478.0\n",
            "         511       0.00      0.00      0.00      66.0\n",
            "         512       0.00      0.00      0.00     308.0\n",
            "         513       0.00      0.00      0.00     110.0\n",
            "         517       0.00      0.00      0.00     187.0\n",
            "         518       0.00      0.00      0.00     152.0\n",
            "         519       0.00      0.00      0.00     135.0\n",
            "         520       0.00      0.00      0.00      78.0\n",
            "         521       0.00      0.00      0.00     151.0\n",
            "         523       0.00      0.00      0.00      80.0\n",
            "         524       0.00      0.00      0.00      14.0\n",
            "         525       0.00      0.00      0.00      71.0\n",
            "         526       0.00      0.00      0.00      60.0\n",
            "         527       0.00      0.00      0.00     271.0\n",
            "         528       0.00      0.00      0.00      17.0\n",
            "         529       0.00      0.00      0.00      42.0\n",
            "         530       0.00      0.00      0.00     131.0\n",
            "         532       0.00      0.00      0.00      33.0\n",
            "         533       0.00      0.00      0.00      89.0\n",
            "         535       0.00      0.00      0.00     136.0\n",
            "         536       0.00      0.00      0.00      27.0\n",
            "         537       0.00      0.00      0.00      43.0\n",
            "         538       0.00      0.00      0.00      10.0\n",
            "         539       0.00      0.00      0.00      11.0\n",
            "         540       0.00      0.00      0.00      33.0\n",
            "         542       0.00      0.00      0.00      27.0\n",
            "         543       0.00      0.00      0.00     114.0\n",
            "         544       0.00      0.00      0.00     168.0\n",
            "         546       0.00      0.00      0.00     231.0\n",
            "         547       0.00      0.00      0.00      24.0\n",
            "         576       0.00      0.00      0.00      19.0\n",
            "         577       0.00      0.00      0.00      13.0\n",
            "         580       0.00      0.00      0.00      26.0\n",
            "         581       0.00      0.00      0.00     108.0\n",
            "         582       0.00      0.00      0.00      16.0\n",
            "         584       0.00      0.00      0.00     298.0\n",
            "         585       0.00      0.00      0.00     103.0\n",
            "         586       0.00      0.00      0.00     301.0\n",
            "         587       0.00      0.00      0.00     107.0\n",
            "         590       0.00      0.00      0.00     498.0\n",
            "         591       0.00      0.00      0.00     109.0\n",
            "         592       0.00      0.00      0.00      42.0\n",
            "         593       0.00      0.00      0.00     258.0\n",
            "         594       0.00      0.00      0.00     391.0\n",
            "         597       0.00      0.00      0.00     503.0\n",
            "         598       0.00      0.00      0.00      72.0\n",
            "         599       0.00      0.00      0.00     100.0\n",
            "         600       0.00      0.00      0.00     141.0\n",
            "         601       0.00      0.00      0.00      12.0\n",
            "         603       0.00      0.00      0.00      44.0\n",
            "         605       0.00      0.00      0.00      24.0\n",
            "         606       0.00      0.00      0.00     106.0\n",
            "         607       0.00      0.00      0.00      27.0\n",
            "         608       0.00      0.00      0.00      31.0\n",
            "         610       0.00      0.00      0.00      58.0\n",
            "         611       0.00      0.00      0.00      70.0\n",
            "         612       0.00      0.00      0.00     181.0\n",
            "         613       0.00      0.00      0.00      48.0\n",
            "         656       0.00      0.00      0.00      14.0\n",
            "         657       0.00      0.00      0.00      38.0\n",
            "         659       0.00      0.00      0.00      64.0\n",
            "         660       0.00      0.00      0.00      59.0\n",
            "         661       0.00      0.00      0.00     118.0\n",
            "         662       0.00      0.00      0.00      91.0\n",
            "         663       0.00      0.00      0.00      15.0\n",
            "         664       0.00      0.00      0.00      41.0\n",
            "         665       0.00      0.00      0.00     308.0\n",
            "         666       0.00      0.00      0.00      28.0\n",
            "         667       0.00      0.00      0.00      40.0\n",
            "         668       0.00      0.00      0.00     102.0\n",
            "         669       0.00      0.00      0.00     375.0\n",
            "         670       0.00      0.00      0.00      21.0\n",
            "         671       0.00      0.00      0.00     111.0\n",
            "         672       0.00      0.00      0.00     156.0\n",
            "         709       0.00      0.00      0.00      39.0\n",
            "         710       0.00      0.00      0.00      44.0\n",
            "         712       0.00      0.00      0.00     170.0\n",
            "         713       0.00      0.00      0.00     254.0\n",
            "         714       0.00      0.00      0.00     312.0\n",
            "         715       0.00      0.00      0.00     217.0\n",
            "         716       0.00      0.00      0.00     453.0\n",
            "         717       0.00      0.00      0.00      32.0\n",
            "         718       0.00      0.00      0.00     448.0\n",
            "         719       0.00      0.00      0.00      17.0\n",
            "         720       0.00      0.00      0.00     259.0\n",
            "         721       0.00      0.00      0.00      95.0\n",
            "         722       0.00      0.00      0.00      47.0\n",
            "         824       0.00      0.00      0.00     237.0\n",
            "         828       0.00      0.00      0.00     369.0\n",
            "         829       0.00      0.00      0.00      22.0\n",
            "         830       0.00      0.00      0.00     101.0\n",
            "         831       0.00      0.00      0.00      80.0\n",
            "         832       0.00      0.00      0.00     123.0\n",
            "         833       0.00      0.00      0.00     100.0\n",
            "         834       0.00      0.00      0.00      69.0\n",
            "         835       0.00      0.00      0.00      37.0\n",
            "         837       0.00      0.00      0.00     560.0\n",
            "         838       0.00      0.00      0.00      14.0\n",
            "         839       0.00      0.00      0.00     218.0\n",
            "         840       0.00      0.00      0.00      76.0\n",
            "         841       0.00      0.00      0.00      70.0\n",
            "         842       0.00      0.00      0.00      87.0\n",
            "         843       0.00      0.00      0.00      20.0\n",
            "         844       0.00      0.00      0.00      50.0\n",
            "         857       0.00      0.00      0.00      16.0\n",
            "         862       0.00      0.00      0.00      82.0\n",
            "         871       0.00      0.00      0.00      11.0\n",
            "         884       0.00      0.00      0.00      33.0\n",
            "         894       0.00      0.00      0.00      13.0\n",
            "         895       0.00      0.00      0.00      61.0\n",
            "         896       0.00      0.00      0.00      17.0\n",
            "         897       0.00      0.00      0.00      20.0\n",
            "         899       0.00      0.00      0.00     157.0\n",
            "         900       0.00      0.00      0.00     182.0\n",
            "         904       0.00      0.00      0.00      50.0\n",
            "         910       0.00      0.00      0.00      52.0\n",
            "         911       0.00      0.00      0.00      73.0\n",
            "         912       0.00      0.00      0.00     124.0\n",
            "         913       0.00      0.00      0.00      10.0\n",
            "        1918       0.00      0.00      0.00      31.0\n",
            "        1923       0.00      0.00      0.00      19.0\n",
            "\n",
            "    accuracy                           0.00   32205.0\n",
            "   macro avg       0.00      0.00      0.00   32205.0\n",
            "weighted avg       0.00      0.00      0.00   32205.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFrW4FEKk9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}